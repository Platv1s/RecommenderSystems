{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Nsuy1LjjQyKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "***\n",
        "\n",
        "## Question 1: Neural Codes & Nearest Neighbor retrieval (7.5pt)\n",
        "The Caltech101 dataset consists of images of 101 different objects. In this question you will develop an image retrieval system using image representations (neural codes) learned with a deep convolutional neural network and a given distance metric.\n",
        "\n",
        "In the tasks below you will need to implement the following steps:\n",
        "\n",
        "* Retrieval for $n$ selected (distinct) query images from the dataset\n",
        "    * For each query image, obtain the 5 most similar images (excluding the query image itself!)\n",
        "* Evaluation of the quality of the retrieval \n",
        "    * The Caltech101 images are annotated with their object class. Use these annotations to evaluate the accuracy of the retrieval task.\n",
        "    * For each query image, count the number of images whose class corresponds to the one from the query. The score of the retrieval for that image then ranges between:\n",
        "        * **5** *all* retrieved images' classes agree with the query image class\n",
        "        * **0** *none* of the images' classes agree with the query image class\n",
        "    * Compute the average of all $n$ queries\n",
        "\n",
        "***\n",
        "\n",
        "### Task 1.1:  Neural codes image retrieval\n",
        "**a)** Implement the retrieval task and evaluate the results for $n=200$ images. Use the provided VGG16 network pre-trained on ImageNet to compute \"neural codes\" and L2-distance. Specifically use the codes produces by the following layers of the model: \n",
        "1. the \"fc1\"-layer\n",
        "2. the \"fc2\"-layer\n",
        "\n",
        "Provide the retrieval evaluation scores for both tasks."
      ]
    },
    {
      "metadata": {
        "id": "skee9Qr2RWLG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea1e4f24-4a3d-4b57-9f7d-f7aa3dbe7d23",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942654112,
          "user_tz": -60,
          "elapsed": 8275,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())\n",
        "!pip install -q keras==2.1.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0GjcnIaEQyKi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# you'll need these imports:\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-9os9OdAiuH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BY5hUF6qQyKm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "dba1a587-8ea3-402e-f6f1-054fb9c96be1",
        "executionInfo": {
          "status": "error",
          "timestamp": 1520938001237,
          "user_tz": -60,
          "elapsed": 478,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# NOTE: you will first need to apply some changes to \"Practical-3.3.0_preprocess-caltech101.ipynb\" and run it\n",
        "#       to obtain a pickle file with \"fc1\"-features. You don't need to show these changes here.\n",
        "\n",
        "\n",
        "# make random selection of n query images/indices, the same for all experiments\n",
        "n = 200\n",
        "n_examples = 8677  # the dataset has 8677 images\n",
        "indices = np.random.choice(range(n_examples), size=n, replace=False)\n",
        "\n",
        "# iterate over two data representations (make sure these two files exist in the \"data\" subfolder first)\n",
        "for datapath in (\"caltech101_VGG16_fc1.p\", \"caltech101_VGG16_fc2.p\"):\n",
        "    # load the dataset\n",
        "    with open(os.path.join(\"data\", datapath), \"rb\") as f:\n",
        "        X_fc, y, X_paths, classes = pickle.load(f)\n",
        "\n",
        "\n",
        "    # === SOLUTION: ===\n",
        "    # insert code here\n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-81b9f4805426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"caltech101_VGG16_fc1.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"caltech101_VGG16_fc2.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mX_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/caltech101_VGG16_fc1.p'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0r5yXfSrQyKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Which representation (\"neural code\") provided better features for the given retrieval task? \n",
        "Justify your answer and discuss possible reasons for the observed results. Relate your answer to the conclusions in the paper \"Neural Codes for Image Retrieval\".\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "fBkfJkccQyKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*=== write your answer here ===*"
      ]
    },
    {
      "metadata": {
        "id": "YxJksBVrQyKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 1.2: Detailed evaluation\n",
        "**a)** The retrieval scores can vary from one query image to another. Some images are quite representative and for them retrieval works well, some are not so much.\n",
        "For the same retrieval task given above using \"fc2\"-features, find (if possible) six query images such that they range from excellent to poor retrieval performance. More specifically find example query images that result in query scores of exactly 0, 1, 2, 3, 4, and 5.\n",
        "\n",
        "Visualise the six (or less) resulting query images."
      ]
    },
    {
      "metadata": {
        "id": "HPqQC_nvQyKq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cb2eb6c-7050-4abb-80c8-cec1eee101bd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942660379,
          "user_tz": -60,
          "elapsed": 517,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# you'll need these extra imports:\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1zN39zDLQyKs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "datapath = \"caltech101_VGG16_fc2.p\"\n",
        "with open(os.path.join(\"data\", datapath), \"rb\") as f:\n",
        "    X_fc, y, X_paths, classes = pickle.load(f)\n",
        "\n",
        "# you can use this simple function to visualise an image, given a filepath\n",
        "def show_img(filepath):\n",
        "    img = image.load_img(filepath, target_size=(224,224))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "# example usage given some index < 8677:\n",
        "#index = 254\n",
        "#show_img(X_paths[index])\n",
        "\n",
        "\n",
        "# === SOLUTION: ===\n",
        "# insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z15AB9DdQyKu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Looking at the results, what can you say about the \"types\" of images that obtain good retrieval scores compared to those obtaining poor retrieval scores? Give an explanation and possible solution(s).\n",
        "\n",
        "(*HINT: How did we obtain data representations for similarity measures?*)\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "0-i1ZpEHQyKu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*=== write your answer here ===*"
      ]
    },
    {
      "metadata": {
        "id": "0b6L_gVEQyKv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 1.3: Subjective evaluation\n",
        "We will now use the \"fc2\"-features to do image retrieval for query images from the \"BACKGROUND_Google\" set from the Caltech101 dataset. These images are not associated to a particular class, so we will evaluate them subjectively instead.\n",
        "\n",
        "**a)** Find two query images from the \"BACKGROUND_Google\" class, such that for the first query image relevant/similar images are retrieved (according to your own definition of relevancy/similarity), and for the second image mainly irrelevant/dissimilar images are retrieved. For each of them, visualise its 5 nearest neighbors in the Caltech101 dataset (*so do NOT retrieve images from the \"BACKGROUND_Google\" class!*), according to the \"fc2-features\" and L2-distance."
      ]
    },
    {
      "metadata": {
        "id": "xMQi6A9OQyKv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load the BACKGROUND_Google set\n",
        "with open(os.path.join(\"data\",\"caltech101_VGG16_fc2_bg.p\"), \"rb\") as f:\n",
        "    bg_fc2, bg_paths = pickle.load(f)\n",
        "\n",
        "\n",
        "# === SOLUTION: ===\n",
        "# insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N9QLJwglQyKy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Motivate your idea of \"relevance\": why do you consider the results for the first image relevant/similar, and those for the second image irrelevant/dissimilar?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "mloxLbeHQyKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*=== write your answer here ===*"
      ]
    },
    {
      "metadata": {
        "id": "wNQno11nQyKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**c)** Explain why you think this retrieval method (nearest neighbor for neural codes from VGG16) performs better on the first image than on the second.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "9PCVqsNSQyK0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*=== write your answer here ===*"
      ]
    },
    {
      "metadata": {
        "id": "KWFnj5fwQyK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 1.4: Dimensionality reduction\n",
        "\n",
        "**a)** So far we've been using 4096-dimensional neural codes. This space is however still quite high-dimensional. Apply a dimensionality reduction method and evaluate the effect on the retrieval performance.\n",
        "\n",
        "* Use PCA to obtain lower-dimensional representations of the Caltech101 data \"fc2\"-features (try the same compression rates as in Table 2 of the \"Neural Codes for Image Retrieval\" paper).\n",
        "* Evaluate the same retrieval task as explained at the start of this question for each of the compression rates/dimensionalities. Report the retrieval scores.\n",
        "\n",
        "*HINT: See http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html on how to transform a dataset with PCA.*"
      ]
    },
    {
      "metadata": {
        "id": "R63ESIs9QyK3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import PCA from scikit-learn\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiRECaEwQyK5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "datapath = \"caltech101_VGG16_fc2.p\"\n",
        "with open(os.path.join(\"data\", datapath), \"rb\") as f:\n",
        "    X_fc, y, X_paths, classes = pickle.load(f)\n",
        "    \n",
        "# make random selection of n query images/indices, the same for all experiments\n",
        "n = 200\n",
        "n_examples = 8677  # the dataset has 8677 images\n",
        "indices = np.random.choice(range(n_examples), size=n, replace=False)\n",
        "\n",
        "\n",
        "# === SOLUTION: ===\n",
        "# insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYwQBYbJQyK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Discuss your results: how much can you further reduce the dimensionality of the data representations, without affecting the retrieval performance (much)? Compare these results to those from the paper, are your conclusions similar or not?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "FqnFpfYmQyK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*=== write your answer here ===*"
      ]
    },
    {
      "metadata": {
        "id": "oPVGe5EiQyK9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## Question 2: Fashion-MNIST (12.5pt)\n",
        "For this question we will work with the \"Fashion-MNIST\" dataset. This dataset is modelled to have the same specifics as MNIST; it consists of a training set of 60,000 examples, and a test set of 10,000 examples. Each example is a 28x28 greyscale image, associated with a label from one of 10 classes. The images represent various clothing items (as opposed to handwritten digits for MNIST), each class represents a different type of clothing item. The following classes exist:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot\n",
        "\n",
        "In this question we will investigate various ways to model visual similarity for this dataset, in order to perform image retrieval. For more info about the dataset, see https://github.com/zalandoresearch/fashion-mnist.\n",
        "\n",
        "The dataset can directly be obtained through Keras:"
      ]
    },
    {
      "metadata": {
        "id": "6SQKxZTVQyK-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 79
            },
            {
              "item_id": 80
            },
            {
              "item_id": 81
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "5d526728-5cc7-422e-96b3-cd6d0c571fa9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942688603,
          "user_tz": -60,
          "elapsed": 20921,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "\n",
        "# load the data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# properties of the data\n",
        "img_rows, img_cols, chns = 28, 28, 1\n",
        "n_classes = 10\n",
        "\n",
        "# reshape\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], chns, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], chns, img_rows, img_cols)\n",
        "    input_shape = (chns, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, chns)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, chns)\n",
        "    input_shape = (img_rows, img_cols, chns)\n",
        "\n",
        "# normalise\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# transform labels to one-hot encoding, but also keep original single-digit encoding\n",
        "y_train_digits = y_train\n",
        "y_test_digits = y_test\n",
        "y_train = to_categorical(y_train_digits, n_classes)\n",
        "y_test = to_categorical(y_test_digits, n_classes)\n",
        "\n",
        "print(\"X_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# show an example\n",
        "example_id = 6000  # pick any integer from 0 to 59999 to visualize a training example\n",
        "example = x_train[example_id].reshape(img_rows, img_cols)\n",
        "label = y_train[example_id]\n",
        "label_digit = y_train_digits[example_id]\n",
        "label_class = classes[label_digit]\n",
        "plt.matshow(example, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(\"Class: {} ({})\".format(label_class, label_digit))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 15s 1us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 4s 1us/step\n",
            "X_train shape: (60000, 28, 28, 1)\n",
            "y_train shape: (60000, 10)\n",
            "X_test shape: (10000, 28, 28, 1)\n",
            "y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD+CAYAAAD1VNNvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f34e0a1afd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Class: Bag (8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Z72ZyKNQyLA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Consider the following situation: We have a fully labelled dataset (the ***labelled set***) of the images from the first 5 classes (t-shirts/tops, trousers, pullovers, dresses, coats). We are then supplied with an unlabelled dataset (the ***retrieval set***) containing the remaining Fashion-MNIST images (sandals, shirts, sneakers, bags, ankle boots) on which we want to be able to perform image retrieval. So we cannot use labels from the retrieval set, since we do not know them (note that in our case we *do* have the labels, but we will only use them for evaluation).\n",
        "\n",
        "The following code splits the dataset up into two sets representing 5 classes each. Observe that the labelled and the retrieval set have exactly the same size."
      ]
    },
    {
      "metadata": {
        "id": "96D3fneIQyLB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "4731219d-1fe7-4972-dc0d-4406357cf41a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942689100,
          "user_tz": -60,
          "elapsed": 466,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# obtain indices of labelled and retrieval sets\n",
        "indices_train_l = np.argwhere(y_train_digits < 5).flatten()  # indices labelled training set\n",
        "indices_train_r = np.argwhere(y_train_digits >= 5).flatten()  # indices retrieval training set\n",
        "indices_test_l = np.argwhere(y_test_digits < 5).flatten()  # indices labelled test set\n",
        "indices_test_r = np.argwhere(y_test_digits >= 5).flatten()  # indices retrieval test set\n",
        "\n",
        "# split up train and test set (images and labels)\n",
        "x_train_l = x_train[indices_train_l]\n",
        "x_train_r = x_train[indices_train_r]\n",
        "y_train_l = y_train[indices_train_l]\n",
        "y_train_r = y_train[indices_train_r]\n",
        "y_train_digits_l = y_train_digits[indices_train_l]\n",
        "y_train_digits_r = y_train_digits[indices_train_r]\n",
        "x_test_l = x_test[indices_test_l]\n",
        "x_test_r = x_test[indices_test_r]\n",
        "y_test_l = y_test[indices_test_l]\n",
        "y_test_r = y_test[indices_test_r]\n",
        "y_test_digits_l = y_test_digits[indices_test_l]\n",
        "y_test_digits_r = y_test_digits[indices_test_r]\n",
        "\n",
        "# labels are now one-hot encoded 10-dimensional vectors, but only the first or last five dimensions are used\n",
        "# omit unused dimensions to obtain 5-dimensional one-hot encodings\n",
        "y_train_l = y_train_l[:, :5]\n",
        "y_train_r = y_train_r[:, 5:]\n",
        "y_test_l = y_test_l[:, :5]\n",
        "y_test_r = y_test_r[:, 5:]\n",
        "# (note that the dimensions of y_train_l/y_test_l do not correspond to those of y_train_r/y_test_r now)\n",
        "\n",
        "# print the shapes\n",
        "print(x_train_l.shape)\n",
        "print(x_train_r.shape)\n",
        "print(y_train_l.shape)\n",
        "print(y_train_r.shape)\n",
        "print(y_train_digits_l.shape)\n",
        "print(y_train_digits_r.shape)\n",
        "print(x_test_l.shape)\n",
        "print(x_test_r.shape)\n",
        "print(y_test_l.shape)\n",
        "print(y_test_r.shape)\n",
        "print(y_test_digits_l.shape)\n",
        "print(y_test_digits_r.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 28, 28, 1)\n",
            "(30000, 28, 28, 1)\n",
            "(30000, 5)\n",
            "(30000, 5)\n",
            "(30000,)\n",
            "(30000,)\n",
            "(5000, 28, 28, 1)\n",
            "(5000, 28, 28, 1)\n",
            "(5000, 5)\n",
            "(5000, 5)\n",
            "(5000,)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "59eXS1jgQyLC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 2.1: Fashion neural retrieval\n",
        "**a)** Design an MLP (multilayer perceptron) for classification on the first 5 classes of the Fashion-MNIST dataset (i.e. only use `x_train_l` for training). You may include Dropout and BatchNormalization if needed. Let the last hidden dense layer (before the 5-dimensional output layer) have 128 dimensions. (*HINT: you can use* `name=\"neural_codes\"` *for this layer to make it easier to obtain features from it later.*)\n",
        "\n",
        "Train it to classify images into their corresponding classes. Make sure that it achieves decent accuracy (at least 90%) on the labelled test set `x_test_l` (show this!). Save the trained model to a \".h5\" file. (make sure you're using Keras version 2.1.3!)"
      ]
    },
    {
      "metadata": {
        "id": "Oj4wH6elQyLD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import sequential model and layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten, Dense, Reshape, InputLayer, MaxPool2D, Dropout\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBDFaTpqQyLF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "344a87d9-1fb6-44da-bb46-1037356ca257",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942700076,
          "user_tz": -60,
          "elapsed": 424,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = Sequential()\n",
        "\n",
        "# encoder\n",
        "mlp = Sequential()\n",
        "mlp.add(Flatten(input_shape=(28,28,1)))\n",
        "mlp.add(Dropout(0.13))\n",
        "mlp.add(BatchNormalization())\n",
        "mlp.add(Dense(128, activation = \"relu\", name=\"neural_codes\"))\n",
        "mlp.add(Dense(5, input_dim=128, activation='softmax'))\n",
        "\n",
        "mlp.summary()\n",
        "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "neural_codes (Dense)         (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 104,261\n",
            "Trainable params: 102,693\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dAuqGTXjVf7a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 76
            },
            {
              "item_id": 149
            },
            {
              "item_id": 214
            },
            {
              "item_id": 229
            },
            {
              "item_id": 230
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "b42fd147-11ba-484a-c252-4cca183346ac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942768136,
          "user_tz": -60,
          "elapsed": 66711,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "epochs = 10\n",
        "\n",
        "mlp.fit(x_train_l,  y_train_l,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_test_l, y_test_l)\n",
        "       )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 7s 227us/step - loss: 0.1414 - acc: 0.9439 - val_loss: 0.1213 - val_acc: 0.9530\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 7s 221us/step - loss: 0.1124 - acc: 0.9554 - val_loss: 0.1070 - val_acc: 0.9594\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 7s 219us/step - loss: 0.1023 - acc: 0.9607 - val_loss: 0.1088 - val_acc: 0.9573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 7s 220us/step - loss: 0.0970 - acc: 0.9619 - val_loss: 0.1065 - val_acc: 0.9586\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 7s 219us/step - loss: 0.0926 - acc: 0.9639 - val_loss: 0.1014 - val_acc: 0.9612\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 7s 220us/step - loss: 0.0894 - acc: 0.9647 - val_loss: 0.1025 - val_acc: 0.9600\n",
            "Epoch 7/10\n",
            " 8520/30000 [=======>......................] - ETA: 4s - loss: 0.0874 - acc: 0.9650"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 6s 214us/step - loss: 0.0858 - acc: 0.9661 - val_loss: 0.1058 - val_acc: 0.9609\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 7s 217us/step - loss: 0.0834 - acc: 0.9672 - val_loss: 0.1061 - val_acc: 0.9614\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 7s 219us/step - loss: 0.0809 - acc: 0.9686 - val_loss: 0.1052 - val_acc: 0.9634\n",
            "Epoch 10/10\n",
            "12480/30000 [===========>..................] - ETA: 3s - loss: 0.0761 - acc: 0.9716"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 7s 220us/step - loss: 0.0795 - acc: 0.9698 - val_loss: 0.1026 - val_acc: 0.9655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34e056d668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "h-iUfL4LQyLK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "mlp.save(\"mlp_fashionmnist_l.h5\")\n",
        "\n",
        "#files.download(\"mlp_fashionmnist_1.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbmBRTbhQyLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Briefly motivate how and why you chose this architecture.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "L-L3DBYJQyLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We chose for the above structure because partially trial and error and from our knowledge both obtained during this course aswell as other courses. Our first layer is a Flatten layer, this layer makes sure that the data structure has the correct shape for the next layers in our model. Our second layer is a Dropout layer, this layer is there to prevent overfitting. During the buidling of our network we had the feeling that it was overfitting so we added a layer to deal with it. The thrid layer is used for normalization. It uses the Batch normalization as proposed by (Ioffe and Szegedy, 2014). Finally we use two dense layers as specified by the assignment. The first dense layer we found out via trail and error that relu was the best activation for it and as specified in the assignment the output of this layer has 128 dimensions. In the last layer we use Softmax as activation and specifiy that the output has to be of 5 dimensions. \n",
        "\n",
        "\n",
        "Using the hereby explained neural network we obtained an accuracy of 97% as can be seen above."
      ]
    },
    {
      "metadata": {
        "id": "Hy-Xe997QyLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 2.2: Fashion neural retrieval #2\n",
        "**a)** Design a CNN (convolutional neural network) for classification on the first 5 classes of the Fashion-MNIST dataset (i.e. only use x_train_l for training), consisting of a number of Convolutions with Max-Pooling, followed by one or more Dense layers. You may use Dropout and BatchNormalization to improve generalization and training speed. Let the last hidden dense layer (before the 5-dimensional output layer) have 128 dimensions. (*HINT: you can use* `name=\"neural_codes\"` *for this layer to make it easier to obtain features from it later.*)\n",
        "\n",
        "Train the CNN to classify images into their corresponding classes. Make sure that it achieves decent accuracy (at least 94%) on the test set `x_test_l` (show this!). Save the trained model to a \".h5\" file. (make sure you're using Keras version 2.1.3!)"
      ]
    },
    {
      "metadata": {
        "id": "md00Cjd8QyLO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import additional layers\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten, Dense, Reshape, InputLayer, MaxPool2D, Convolution2D, Dropout\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J2r2pCn8QyLR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "90a15a77-9f22-47d2-d657-e07a34dbe49c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942770056,
          "user_tz": -60,
          "elapsed": 587,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2), padding=\"same\"))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dropout(0.17))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Dense(128,activation='relu',name='neural_codes'))\n",
        "cnn.add(Dense(5,activation='softmax'))\n",
        "\n",
        "cnn.summary()\n",
        "cnn.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 5408)              21632     \n",
            "_________________________________________________________________\n",
            "neural_codes (Dense)         (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 714,949\n",
            "Trainable params: 704,133\n",
            "Non-trainable params: 10,816\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v-8O_CaBrzdm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 98
            },
            {
              "item_id": 202
            },
            {
              "item_id": 286
            },
            {
              "item_id": 372
            },
            {
              "item_id": 421
            },
            {
              "item_id": 422
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1999a8f4-5e7b-4202-c7e4-b4dd2363a5d0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942881749,
          "user_tz": -60,
          "elapsed": 111297,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "epochs = 10\n",
        "\n",
        "cnn.fit(x_train_l,  y_train_l,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_test_l, y_test_l)\n",
        "       )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 12s 402us/step - loss: 0.1091 - acc: 0.9584 - val_loss: 0.0872 - val_acc: 0.9690\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 11s 367us/step - loss: 0.0745 - acc: 0.9715 - val_loss: 0.0824 - val_acc: 0.9720\n",
            "Epoch 3/10\n",
            " 6180/30000 [=====>........................] - ETA: 8s - loss: 0.0615 - acc: 0.9771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 11s 362us/step - loss: 0.0616 - acc: 0.9760 - val_loss: 0.0812 - val_acc: 0.9726\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 11s 367us/step - loss: 0.0530 - acc: 0.9799 - val_loss: 0.0784 - val_acc: 0.9742\n",
            "Epoch 5/10\n",
            "18840/30000 [=================>............] - ETA: 3s - loss: 0.0434 - acc: 0.9839"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 11s 366us/step - loss: 0.0446 - acc: 0.9834 - val_loss: 0.0960 - val_acc: 0.9711\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 11s 363us/step - loss: 0.0394 - acc: 0.9845 - val_loss: 0.0863 - val_acc: 0.9742\n",
            "Epoch 7/10\n",
            "21840/30000 [====================>.........] - ETA: 2s - loss: 0.0336 - acc: 0.9869"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 11s 364us/step - loss: 0.0356 - acc: 0.9864 - val_loss: 0.1661 - val_acc: 0.9586\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 11s 364us/step - loss: 0.0325 - acc: 0.9877 - val_loss: 0.1030 - val_acc: 0.9735\n",
            "Epoch 9/10\n",
            "22920/30000 [=====================>........] - ETA: 2s - loss: 0.0280 - acc: 0.9900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 11s 360us/step - loss: 0.0287 - acc: 0.9896 - val_loss: 0.1190 - val_acc: 0.9708\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 11s 366us/step - loss: 0.0247 - acc: 0.9908 - val_loss: 0.1206 - val_acc: 0.9710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34dde12630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "k3cT4_reQyLS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "cnn.save(\"cnn_fashionmnist_l.h5\")\n",
        "\n",
        "#files.download(\"cnn_fashionmnist_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGI0SHYNQyLT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Briefly motivate how and why you chose this architecture.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "l6yydsnqQyLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the architecture of the convolunational neural network we choose for only one convolutional layer and only one maxPooling2D layer. Because using trial and error we found that that was the best. Adding more layers both convolutional as maxpooling layers did not further improve the accuracy.  The rest of the architecture looks very similair to the architecture of our MLP network. We thought that if it worked quite well with out the maxPooling it might as well work after maxPooling. So we tried that and immediately found that the accuracy reached the 97% with ony one Conv2D layer and one maxPooling2D layer."
      ]
    },
    {
      "metadata": {
        "id": "ObOftpBQQyLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 2.3: Fashion neural retrieval #3\n",
        "**a)** Design a (convolutional) Denoising Autoencoder (DAE) for the *full* Fashion-MNIST dataset (i.e. use `x_train`, *not* `x_train_l`). For the encoder, use only Convolutional layers and Max-Pooling, followed by a Dense layer with 128 units. The output of this layer will be the \"code\" of the autoencoder (*HINT: you can use* `name=\"neural_codes\"` *for this layer to make it easier to obtain features from it later*). For the decoder, start with a Dense layer to upscale to a suitable dimension, and then use only Convolutional layers and UpSampling. You may use BatchNormalization to speed up training.\n",
        "\n",
        "Train the DAE to reconstruct noisy images to the original input images. Make sure that it achieves a binary cross-entropy loss of at most 0.29 on the test set (show this!). Save the trained model to a \".h5\" file. (make sure you're using Keras version 2.1.3!)"
      ]
    },
    {
      "metadata": {
        "id": "FiUaCoZPQyLV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import additional layer\n",
        "from keras.layers import UpSampling2D, Reshape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jWszOWY9QyLX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "54de072e-addf-420b-f5c5-f5e687c55eb9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520942887379,
          "user_tz": -60,
          "elapsed": 4246,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# obtain noisy version of data\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "\n",
        "# define autoencoder\n",
        "dae = Sequential()\n",
        "\n",
        "# === SOLUTION: ===\n",
        "# encoder\n",
        "dae.add(Conv2D(32, (3, 3), activation='elu', padding='same', input_shape=input_shape))\n",
        "dae.add(MaxPooling2D((2, 2), padding='same'))\n",
        "dae.add(BatchNormalization())\n",
        "dae.add(Conv2D(32, (3, 3), activation='elu', padding='same'))\n",
        "dae.add(MaxPooling2D((2, 2), padding='same'))\n",
        "dae.add(BatchNormalization())\n",
        "dae.add(Flatten())  \n",
        "dae.add(Dense(128, activation='elu', name=\"neural_codes\"))  \n",
        "\n",
        "\n",
        "# decoder\n",
        "dae.add(Dense(1568))  \n",
        "dae.add(Reshape((7, 7, 32)))\n",
        "dae.add(Conv2D(32, (3, 3), activation='elu', padding='same'))\n",
        "dae.add(UpSampling2D((2, 2)))\n",
        "dae.add(BatchNormalization())\n",
        "dae.add(Conv2D(32, (3, 3), activation='elu', padding='same'))\n",
        "dae.add(UpSampling2D((2, 2)))\n",
        "dae.add(BatchNormalization())\n",
        "dae.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
        "\n",
        "dae.summary()\n",
        "dae.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "neural_codes (Dense)         (None, 128)               200832    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1568)              202272    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 32)          9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 431,969\n",
            "Trainable params: 431,713\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LX5G9VfQt8pg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 164
            },
            {
              "item_id": 343
            },
            {
              "item_id": 500
            },
            {
              "item_id": 641
            },
            {
              "item_id": 776
            },
            {
              "item_id": 908
            },
            {
              "item_id": 1039
            },
            {
              "item_id": 1168
            },
            {
              "item_id": 1294
            },
            {
              "item_id": 1299
            },
            {
              "item_id": 1300
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4ca92585-2be8-491f-fb67-708742a59945",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520943227317,
          "user_tz": -60,
          "elapsed": 339807,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "dae.fit(x_train_noisy, x_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_split=1/12)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 36s 656us/step - loss: 0.3093 - val_loss: 0.2946\n",
            "Epoch 2/10\n",
            "10112/55000 [====>.........................] - ETA: 26s - loss: 0.2926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 610us/step - loss: 0.2917 - val_loss: 0.2909\n",
            "Epoch 3/10\n",
            "36416/55000 [==================>...........] - ETA: 11s - loss: 0.2882"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 613us/step - loss: 0.2882 - val_loss: 0.2914\n",
            "Epoch 4/10\n",
            "46784/55000 [========================>.....] - ETA: 4s - loss: 0.2861"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 612us/step - loss: 0.2861 - val_loss: 0.2876\n",
            "Epoch 5/10\n",
            "50912/55000 [==========================>...] - ETA: 2s - loss: 0.2847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 33s 608us/step - loss: 0.2847 - val_loss: 0.2884\n",
            "Epoch 6/10\n",
            "52448/55000 [===========================>..] - ETA: 1s - loss: 0.2836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 614us/step - loss: 0.2836 - val_loss: 0.2874\n",
            "Epoch 7/10\n",
            "53120/55000 [===========================>..] - ETA: 1s - loss: 0.2826"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 614us/step - loss: 0.2826 - val_loss: 0.2858\n",
            "Epoch 8/10\n",
            "53376/55000 [============================>.] - ETA: 0s - loss: 0.2818"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 616us/step - loss: 0.2819 - val_loss: 0.2857\n",
            "Epoch 9/10\n",
            "53472/55000 [============================>.] - ETA: 0s - loss: 0.2811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 611us/step - loss: 0.2812 - val_loss: 0.2864\n",
            "Epoch 10/10\n",
            "53216/55000 [============================>.] - ETA: 1s - loss: 0.2806"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 33s 602us/step - loss: 0.2807 - val_loss: 0.2862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34dc52cda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "GVFKJlAAQyLZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "dae.save(\"dae_fashionmnist_l.h5\")\n",
        "\n",
        "#files.download(\"dae_fashionmnist_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQd3ecq0QyLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Briefly motivate how and why you chose this architecture.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "Wy-INYZ2QyLc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We chose for this architecture based on the architecture of the Denoising Autoencoder from practical 4.1. In this practical an Denoising Autoencoder was build for the MNIST dataset. We tried different activation functions for the different layers of the model. For the convolutional layers we found that relu provided better results than eelu so we sticked by the activation function relu. For the last layer we tried out sigmoid (the same as in the practial) but also hard_sigmoid and tanh. We expected tanh to do better since it is 0 based, however it performed much worse so we sticked with sigmoid as activation function for the last layer. "
      ]
    },
    {
      "metadata": {
        "id": "KBTbmap8QyLd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "Visualise a few test examples, their noisy versions, and their reconstructions."
      ]
    },
    {
      "metadata": {
        "id": "8WA27ubjQyLd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            },
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "3a980302-c659-4c70-ef1b-8f67578393b4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520934282127,
          "user_tz": -60,
          "elapsed": 4288,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# NOTE: you don't need to change this code, just run it after having trained the DAE\n",
        "def plot_examples(x):\n",
        "    n = 10\n",
        "    plt.figure(figsize=(20, 2))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(1, n, i+1)\n",
        "        plt.imshow(x[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "\n",
        "x_test_reconstr = dae.predict(x_test_noisy, batch_size=batch_size)\n",
        "\n",
        "plot_examples(x_test)\n",
        "plot_examples(x_test_noisy)\n",
        "plot_examples(x_test_reconstr)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAABUCbyoAQAAAAAAAACoEv4PZPZXQz5cYEEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f233506f630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB6uE/wocPCrEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2334e91f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f233b262eb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4cHWbZm1QyLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**c)** Do you consider the results acceptable? Do you think they can be useful for image retrieval? Explain why in one or two sentences.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "S_8NheqRQyLf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We think the obtained results are indeed acceptable. The images reconstructed via our Denoising Autoencoder are recognisable except for the flipflop. However based on the noisy image of the flipflop seems like random pixels. In other of the noisy pictures there is some form recognizable. Another unrecoginizable thing is the text \"LEE\" on the second example picture. This is most likely due to the lack of training material for such strings.\n",
        "\n",
        "We think that the can be used for image retrieval since no picture is ever without noise. If you know beforehand what kind of images you will get it is possible to train a Denoising Autoencoder and have it work to obtain pictures which should be somewhat the same as which you were trying to retrieve."
      ]
    },
    {
      "metadata": {
        "id": "5g4UMQY4QyLf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**d)** Why can we train on the full dataset `x_train` here, whereas in Tasks 2.1 and 2.2 we had to use `x_train_l` (the first 5 classes only) for training?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "QNzZbGaAQyLg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can do that here because we artifically add noise to the different images. Because of this none of the images which were originally in the set is still in the training sets. We can use a different noise function to obtain a test set which can be quite different than the training images. In the tasks 2.1 and 2.2 this was impossible so we needed to split up the set in order to have a training and test set. We do not need the labels from the training set to validate just the original image for DAE training. "
      ]
    },
    {
      "metadata": {
        "id": "Hrg1qEQtQyLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 2.4: Fashion neural retrieval #4\n",
        "Autoencoders come in different shapes and sizes. One key defining property of autoencoders is the means the model uses to prevent the learning of the identity function. Typically, this is done with different regularization methods. In the previous task you used a model that uses noise as a regularizer. In this task you will develop a Sparse Autoencoder (SAE). A sparse autoencoder uses a sparsity regularization to obtain sparse representations of the input data. Sparsity can be achieved by using L1-regularization on the activations of the hidden \"code\" layer.\n",
        "\n",
        "\n",
        "**a)** Design a (convolutional) Sparse Autoencoder (SAE) for the *full* Fashion-MNIST dataset (i.e. use `x_train`, *not* `x_train_l`). For the encoder, use only Convolutional layers and Max-Pooling, followed by a Dense layer with 128 units. The output of this layer will be the \"code\" of the autoencoder (*HINT: you can use* `name=\"neural_codes\"` *for this layer to make it easier to obtain features from it later*). Add an activity regularizer to this layer, using `regularizers.l1(10e-5)` from Keras.\n",
        "For the decoder, start with a Dense layer to upscale to a suitable dimension, and then use only Convolutional layers and UpSampling. You may use BatchNormalization to speed up training.\n",
        "\n",
        "Train the SAE to reconstruct input images. Make sure that it achieves a loss value of at most 0.31 on the test set (show this!). Save the trained model to a \".h5\" file. (make sure you're using Keras version 2.1.3!)"
      ]
    },
    {
      "metadata": {
        "id": "kS5oJDTAQyLk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import regularizers for sparse autoencoder\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPuHQDPwQyLo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "b2bb8c5f-3565-4072-ab7d-975569bdb370",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520943229702,
          "user_tz": -60,
          "elapsed": 669,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define autoencoder\n",
        "sae = Sequential()\n",
        "\n",
        "# === SOLUTION: ===\n",
        "# insert code here\n",
        "\n",
        "sae.add(Conv2D(32, (3, 3), activation='elu', padding='same', input_shape=input_shape))\n",
        "sae.add(MaxPooling2D((2, 2), padding='same'))\n",
        "sae.add(BatchNormalization())\n",
        "sae.add(Conv2D(32, (3, 3), activation='elu', padding='same'))\n",
        "sae.add(MaxPooling2D((2, 2), padding='same'))\n",
        "sae.add(BatchNormalization())\n",
        "sae.add(Flatten())  \n",
        "sae.add(Dense(128, activation='elu', activity_regularizer=regularizers.l1(10e-5), name=\"neural_codes\"))  \n",
        "\n",
        "\n",
        "# decoder\n",
        "sae.add(Dense(1568))  \n",
        "sae.add(Reshape((7, 7, 32)))\n",
        "sae.add(Conv2D(32, (3, 3), activation='elu', padding='same'))\n",
        "sae.add(UpSampling2D((2, 2)))\n",
        "sae.add(BatchNormalization())\n",
        "sae.add(Conv2D(32, (3, 3), activation='elu', padding='same'))\n",
        "sae.add(UpSampling2D((2, 2)))\n",
        "sae.add(BatchNormalization())\n",
        "sae.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
        "\n",
        "sae.summary()\n",
        "sae.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "neural_codes (Dense)         (None, 128)               200832    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1568)              202272    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 32)          9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 431,969\n",
            "Trainable params: 431,713\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zBnHSyNQ1SAp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 166
            },
            {
              "item_id": 363
            },
            {
              "item_id": 521
            },
            {
              "item_id": 665
            },
            {
              "item_id": 803
            },
            {
              "item_id": 938
            },
            {
              "item_id": 1014
            },
            {
              "item_id": 1142
            },
            {
              "item_id": 1266
            },
            {
              "item_id": 1273
            },
            {
              "item_id": 1274
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e91fbff8-4665-4d06-d567-4cd96f86027a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520943574431,
          "user_tz": -60,
          "elapsed": 344502,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "sae.fit(x_train_noisy, x_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_split=1/12)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 36s 653us/step - loss: 0.3793 - val_loss: 0.3353\n",
            "Epoch 2/10\n",
            "10112/55000 [====>.........................] - ETA: 27s - loss: 0.3277"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 621us/step - loss: 0.3124 - val_loss: 0.3004\n",
            "Epoch 3/10\n",
            "36416/55000 [==================>...........] - ETA: 11s - loss: 0.2992"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 621us/step - loss: 0.2982 - val_loss: 0.2978\n",
            "Epoch 4/10\n",
            "46880/55000 [========================>.....] - ETA: 4s - loss: 0.2952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 619us/step - loss: 0.2949 - val_loss: 0.2957\n",
            "Epoch 5/10\n",
            "50976/55000 [==========================>...] - ETA: 2s - loss: 0.2925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 624us/step - loss: 0.2926 - val_loss: 0.2934\n",
            "Epoch 6/10\n",
            "52544/55000 [===========================>..] - ETA: 1s - loss: 0.2910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 624us/step - loss: 0.2910 - val_loss: 0.2934\n",
            "Epoch 7/10\n",
            "53216/55000 [============================>.] - ETA: 1s - loss: 0.2898"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 624us/step - loss: 0.2898 - val_loss: 0.2918\n",
            "Epoch 8/10\n",
            "53376/55000 [============================>.] - ETA: 0s - loss: 0.2890"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 616us/step - loss: 0.2888 - val_loss: 0.2960\n",
            "Epoch 9/10\n",
            "53504/55000 [============================>.] - ETA: 0s - loss: 0.2879"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 619us/step - loss: 0.2879 - val_loss: 0.2933\n",
            "Epoch 10/10\n",
            "53152/55000 [===========================>..] - ETA: 1s - loss: 0.2870"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 34s 616us/step - loss: 0.2871 - val_loss: 0.2923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34da1e2198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "Mku2we4SQyLp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "sae.save(\"sae_fashionmnist_l.h5\")\n",
        "\n",
        "#files.download(\"sae_fashionmnist_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgVN1qCOQyLs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Briefly motivate how and why you chose this architecture.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "MAdXOkBHQyLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We chose for this architecture because it already obtained satisfactory results in the previous question with the DEA. We thought and hoped that it would perform equally good. "
      ]
    },
    {
      "metadata": {
        "id": "IAAqeS2ZQyLu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "Visualise a few test examples and their reconstructions."
      ]
    },
    {
      "metadata": {
        "id": "ocfhXJQpQyLv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "5d903b11-9761-4012-b7ae-ff84c4d21dd4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520936131675,
          "user_tz": -60,
          "elapsed": 4047,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# NOTE: you don't need to change this code, just run it after having trained the SAE\n",
        "def plot_examples(x):\n",
        "    n = 10\n",
        "    plt.figure(figsize=(20, 2))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(1, n, i+1)\n",
        "        plt.imshow(x[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "\n",
        "x_test_reconstr = sae.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "plot_examples(x_test)\n",
        "plot_examples(x_test_reconstr)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAABUCbyoAQAAAAAAAACoEv4PZPZXQz5cYEEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2334e91e10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnWmsldUVhredRQYBARER8IJMEhTE\nCRzqUNFWi001bY2pTdo0TZpq0rR/aowmNk1qW0Mbq6lJ0zbBpGpjk8YfOGvEiiKDDA5M96LMg2BF\nO9sfht13v969/e6FC9/5zvP8Woe97z7f2fM5rHeto95///0AAAAAAAAAAABHno8d6QcAAAAAAAAA\nAIAP4IcaAAAAAAAAAICawA81AAAAAAAAAAA1gR9qAAAAAAAAAABqAj/UAAAAAAAAAADUhE+UCo86\n6ihSQh0h3n///aMOVVtHchw//elPR3vixInRPuqo9ON1dXVF+5133snW++QnPxntCRMmJGUnnHBC\ntJcuXRrtHTt2JPUOZ6azQzWOdVmLI0aMiPYDDzyQrfef//wn2t7f7733XrR1PEMI4a233or2SSed\nFO3LLrssqff2229XfOKDpylrUfv6kUceiXZnZ2dST9fL0KFDo/3Pf/4zqffxj388W6Zj/NJLL0X7\n/vvvT+qxFnvGJz7x/yNb97uLL744qTd69Ohob968Odq6t4YQQv/+/aN98sknJ2WrVq2K9jPPPBPt\nnTt3JvV87PuSpqxF5Stf+Uq0b7zxxqRs37590T722GOjvXfv3qTef//732gPHjw4KdPxP+6446L9\n5JNPJvV+/OMfR/vf//53pWfvLU1Yi7r/DRgwINodHR1JPd1D9+zZk21P17avsV27dkVb17COewit\nuZ+GUJ+1+LGP/f//rnUPDSGE73//+9EeOXJktH2sjj766Gj/4Q9/SMoWLVoU7cO5b5ZowlpU/DtD\nb+ppma8pfV2XrMlNXIvtSG4c8agBAAAAAAAAAKgJ/FADAAAAAAAAAFATjiq5buECdeSosyubuwyO\nGTMm2nfddVdSNnv27Gj369cv26a6Wr/77rvZ9/rUpz4V7c985jNJmc5lld7s378/qXfrrbdG+557\n7sk+x6GgaW6l8+fPj/Z3vvOdpEzdhqvi+4+6A+tYX3jhhUk9dSHua+q8FnuCuuBv2bIl2i6H+de/\n/hVtdeP28dW1olInb3PlypXR/vKXv5zUa0VX/b7eT3VfGzVqVFI2Z86caKtkZvLkyUm94cOHR3vb\ntm3RLkkldH6EkM6RJ554ItoqpQkhhD//+c/RfvPNN5Myn1sHS1PWoo659plKk0JIzzGV2pTa8/n0\n97//Pdoqf9RzNoRUSqd/0xfUdS2W8P7X9aLS3Isuuiipd+6550Zb70Au+/3HP/4RbZUahhDCH//4\nx2jr2ecSYF3ffb23NnEt6nl3ySWXJPUWLFgQbZWM7t69O6mnY+z34Z/97GfRVvminrkhfHif7kta\ncS2WqCp9KlEXSVNVmrIW2x2kTwAAAAAAAAAANYcfagAAAAAAAAAAagI/1AAAAAAAAAAA1IRiem6A\n7njwwQeT13Pnzo22665Va6u260hzqS5LWlHV73v7+hyervTnP/95tG+55ZakbObMmdF+4403su/d\nruhYe1wSH/sD+Bjm5kQIaYwaTe1+zjnnJPUOZ4yapqDpfRVPGavjpbEqfBy1TOMrhJBq7jVeisd5\n6Os0wHVF+8Hn9nnnnRft0047LSnT9aJ9/NxzzyX1NIaC1hs4cGBST9ebx/zSZ9R0tGeffXZS7/Of\n/3y0PbbJvffeG+0HHngg2q0WA+BQo7EwhgwZEm1P2avrSsejtKd6mcYx0bXo+7Xut30do6au+P6k\ndxHfP8eOHRttje/jsX90j9N15O+lMaF0ToQQwtSpU6Ot4/nKK68k9TQmlM8lvy+1E5r6XGPfhZCO\n3bhx46Ltadaff/75aJ900knR9thtem/08033Tn2m1atXZ9vwtdjO43iwtPu5A60JHjUAAAAAAAAA\nADWBH2oAAAAAAAAAAGoC0ieoxIwZM6L9hS98ISlTt2uXQCjqIupuvyqF0vZ6Io3Q9kvpDfW9PCXt\nsmXLou2pUtsV7S9Nxe59nEvP7e6m2p7/Ta7smmuuSeppmkuoxuzZs7v9dx8DdQ0vuQq7VEZRuY2u\nsUGDBiX1PLVpk9G5PXr06Gh/8YtfTOrpeHj/6H64a9euaKvUKYR03HScfM2qW71LJXSP1vHUdN8h\npHIal2z88Ic/jPaKFSui/dprr4V2RuViKoHw807lSaXzrSQndalH7t9V2rNv377sszcNXZcjRoxI\nylTiovM8hFRSrWPoUtJ169ZFWyVvPtYvvvhitDds2JCUvfXWW9HWPXT69OlJPV2bmvY9hFQydTjT\nPx8J/Jw566yzou3STd2zdJ/zlNkqMzvmmGOy7617m5+fOp8mTJgQ7SuuuCLbxmOPPZaULV++PNpN\nH8fegLwJmgYeNQAAAAAAAAAANYEfagAAAAAAAAAAagI/1AAAAAAAAAAA1ARi1EAl7rjjjmirHjuE\nNC5NKR5JSUefw1MRllKU6nOo/ttjcJRi5ai2WTX8Hr+hndC0rdonruHW8dBx91TsJXJpZnOppaE6\nGmdK15Wn/8zFCfKYFjo+vicoGpdB09OG0F4xanSvOfPMM6OtcZ9CSNP0esyv9957L9qlMdTx0BTD\npZS9HjMjl35dY+M43r6+t8Y2a/cYNTfccEO0dR1VPRf9TNNYNr4Wc2ewtzFx4sRod3V1VXqOJqAx\nnMaPH5+U6Z7nY6MxXzQejK8B3eM0hozXW7p0abd/4691Lfq61/1B157/ndZrCnrOXHvttUmZnjs+\n7zdu3Bht3Q89Bpved3bu3Bltj0n0+uuvR9vHWGM/6fv6/Ubj5sybNy8p0/fr7OwMANBs8KgBAAAA\nAAAAAKgJ/FADAAAAAAAAAFATkD5BJSZNmhTtkrzJ3a5z6V9dDqMup+pu7NKnXAroEFLXfXUFd3mT\nSnlK0qpLL7002g8//HD2fZuOjn1VtB9dUqFjWBpPZeDAgT1+BkiZPHlytHXe/+1vf0vq6ZiUUnCX\n1lFOKjhq1Kjk9apVqwpP3Cx0X7vsssui7Wl/33333Wi79EnlFzpupbTbuif7OOna9D05V+b7v9Zz\nOaT+ne6nv/jFL5J67ZZSdcqUKdHWsSvtlTp/vJ72n0sUta7Op379+iX1pk6dGu1HHnmk/AFaHJ2X\nera4XEjvEbrfhZDKh7Zv3x5tlyOtX78+2ppa+Z133knqbd68Odp+Z9Gx8mfMPa/X0zmi0h3fY1qV\nadOmRfuiiy5KyrTfPfW89rWeWz7euk737t0bbZepqSTO16KOo65tP4N1zaoMKoQQLr744mj/7ne/\ni7bv7QDQDPCoAQAAAAAAAACoCfxQAwAAAAAAAABQE5A+hXxWmr5wx1Y3S5cJuTtzndCI+qV+cfdL\ndQ9Wd1t39dy6dWu01TVVZQAhpK717rqtLqLHH398tIcOHZrUO+mkk6Lt0hsdn9mzZ0e7naVPV155\nZaV6Op+1X12Woe7ZvvZyUqhSViGoho6Dunj7WtS1ru7fLmtR1/q33norKdN1qy7+7TyOOu9VHrF2\n7dqknrrL+16rr0tZn3Qd6R7sa7Gqu7yOm36OEFJ5nM6dENLPcsYZZ3TbXggfnltNw/e1wYMHR7v0\n2XP3BZ8XWlbK+lQa7xNOOCFb1mR07aiEKYRUqunzXiUuusd5RiVtX/+mVM/ni66x0vmpd0iX3eTa\ncJlqq8oQdax27NiRlJVk9zlK8nyVqfkdNXcPKrVfkg77+Og6Lclam0xpDFt1/gLkwKMGAAAAAAAA\nAKAm8EMNAAAAAAAAAEBN4IcaAAAAAAAAAICa0DYBA1TL2b9//6RMtZ2q4XftaVXto+onXbOvsVNc\no7xr165K7R8JNB5MSR/qetp169ZFu7OzM9pdXV1Jvb/+9a/RVp24p45Ubf+IESOSsrFjx0ZbUxH7\nuGk9/yxaV9MgtjPXX399t/9eStOuvPnmm8nrjo6O7N/oa12LTY9hcTjQGFHan1u2bEnqHXPMMd3W\nc93/hRdemH0v3dt0X2tKKtjeoDEjjj322Gh7CnSt5/GDdDw0zkQpLbbGrfA4aFrPY5tofAWt52lr\nczGNQkjPUC3zc7Hp69vvHDrGuib8zqF9pmewnqshhDBo0KBoa6yOENJ9Wtv3/dtjvrULes54Wmxd\np54mWeNy6bryNnxNHKAUp8nPRZ0vul94bCrFY5Zo+x6rqlXRftLYLXv27EnqaZ957B7tQx07j0mU\ni/vld97cHcZfa3vehs6n/fv3J2X6XPq52ulsJQ4NtBN41AAAAAAAAAAA1AR+qAEAAAAAAAAAqAlt\nI31S1+PPfvazSZmmht62bVu3dghl92x1Y9S0tdOmTUvqqSvtU089lZTVLT23uliWUoOqq6e7bi9Z\nsiTaKoHwlLSrV6+Otrr7u/uuyjd03EJIXT/VDdb71V2TFXVN1TTe7YzK9ZRSam2dI1dddVVSb82a\nNdn30ja1PR9r6Dma9l7XgKcQVQmEuvc/9NBDSb3LLrss+17qGq6yDJfBtRPa59rH7rI+bNiwaLtL\nvMrSStInRV37XW6h+6uXqWRDz0+XLakkRJ8vhDQdsbahElav10T8HqBzQc8cl1vo2tF1Om/evKTe\nbbfdFu2vfvWrSZnOjVLqd5diN5lcmnvvA12nLl/TsdLx9H7NpWj2e4iuPz9bc+mafc2WpPsqoWmi\n1FDvKXpPDCGVu/sY58bH97lcOm2XUun4+xjr32n7Ph76PcHvwDrmvl8AwP/RteISc70X9fV3b907\neiPbw6MGAAAAAAAAAKAm8EMNAAAAAAAAAEBN4IcaAAAAAAAAAICa0NgYNa4NnTRpUrTPO++8pCwX\n92T58uXZet7+8OHDu32vWbNmJfU0RsPChQuTsrqlnMul5PaUg7m4IiHkUwbu3bs3eZ3TYLs+N6cT\nDiFNM6y2x5rRfvbn1c+m8QHaGddqHyCn7Q4hHfdXX301KVM9aCkFpo5102NYHA6WLl0a7euuuy7a\nvhZ1XWnZo48+mtTT8fGYChpnSmOdaJyqdiMXy8X3/YEDB0ZbYwSFkK4r3Sc1/lAIH9ZjH8DXrMe4\nqFJWip9x3HHHJWUaJ0P31lNOOSWp19XVlX2OJnDJJZckr3Nnpo+b3jN039ywYUNS784774y2x6jJ\n7dM+jhrHo53I7Xde5nNb163GGPHYMFqvdI/K/Y3XVXvEiBFJvd27d0fb44FpjBr9XHW7d/YE3aNO\nPvnkaO/YsSOppzELfU/VsdO+KPVLKSaRlnnsmVysCr8HjR49OtoeK1Pb11g27Xy2HmwMEGhddD2M\nGzcuKfva176WLVu8eHG0//KXv0R78+bNB/1MfuZOmDAh2hobJ4QQNm3a9NHtHfQTAQAAAAAAAADA\nIYEfagAAAAAAAAAAakKjpE/q/qbu4yGEcMEFF0Rb3ZBCSKUdHR0d0T711FOTetu3b4+2u4VPnjw5\n2iNHjoy2pystSXfqhvahu0krWuau22eeeWa0Vb7i0jFNfaku3iqbCCEdO5dVqeurSs7crVRdh/1z\naVlJFtBO5Ma+NCdefvnlbJm6l2sq4lKbzz33XOkRoQLLli2Ltrpm+h6lkj9dD+5OXnI3Vvd/df9+\n5513evrYjUGlE2q7BGLAgAHR9n7VM6gkt9D9VPdkTyWr+J6se6/avp9qulsv08+inH766clrl9U1\nDb0ThJCOuY5xKdVvaU9duXJltD2lu46rjqPLMup+H+krdCxUshlCKiXy+4DeG7Ws1K+lO4XuyVUl\niS7H0j3a99qcxKeV0b7I3SFDCGHw4MHRdhl1bt77vpxLn+53lqphAkrjMXTo0Gh7qnH9O5U+NZ3c\nPhZCesaV5Gva/6V09U1ZH61M6Xulfk//1re+Fe2zzz47qafhOxxdY7o/zJ8/P6nnd6scun+7zEql\nyUuWLEnKbr311o9uu9ITAAAAAAAAAABAn8MPNQAAAAAAAAAANaFR2g51Gz7ttNOSsjFjxkTb3RE1\nIry6s2rk9RBSeZO7KOfcLt2tUp/DXc3d/e5I458/R86NO4QQpk2bFm11yXb52ZVXXhntkpu9upe5\nC6vW1QwW6pofQtrP7hpXygjVLpRceXMZLJxrr702W6YSnM997nNJWa7Pn3/++Wx7UI2NGzdGW9es\n71G6PlQK4FJD/Tsv0z1QMxK5LKPJ+PrQ7HPqdu1niZ5B7vaekxn5PqZtqHt8SVJRcvfW9vy9dI74\nZ1GXZZ0vl19+eVLvpz/9afa9m4BLn3L4/qfjPW/evOzflWRwOk8044Sv+3bNcqh7ofedSg39LqJz\nXcs8S6KOjctMFb0Pehu6b2o9z9SlmZ78PlnKMtWqaD/pvdHXkUrEOjs7kzI9q3R/dPlUTqLo9/jS\nvbGqnF6/k+i5HUK636rc3yUVrYiemS5vOuecc6J9/vnnJ2X6vUrb8Axfugb0Tvnkk08m9VSe7+um\n6h0Y+VTP0buKZi+86qqrknq67+n684xKpT1P5Unjx4+Ptt9hFixYEG3/zqnhQTS8ij/vzJkzo62S\nqxBCuP3227PPeID2/CYKAAAAAAAAAFBD+KEGAAAAAAAAAKAm8EMNAAAAAAAAAEBNaPkYNapP0xgy\nV1xxRVJPtW+uzVbNvWpeXXta0k+qHlG1rd6GamVdr+z6uiONa+kO4LpM/eweD0b7XeMVuN5b29Q+\nc52n6n81pVoI6bjqOLpWWzW+rsvPpV103XET9d49pTQPNm3alP27RYsWRdtj1OR0vZs3b+7NI4Kg\n6Vo1RoqvgZz+3ue8rrdSvC3Ve7eTbtvXh+73Oha+j+neqH0XQroPaeprj/2T208dHQ+Pn5AbK0+V\n2dXVFW3XcOvc2rNnT7Q1Xk874GNcSiGraN9W3QO3bNmSvD7xxBOjrfPEx1tjSbUrvsfpncznva4/\nXZe+3vQ+WIpfUkpHm4spNnz48KReKc5QLtZcK6P3PO3bUqwsjz2jfVuKOZK7G/o6Ku23uXni30n0\nc/ln0bEbMmRI9r1aBe2/Sy65JNoatzKEEObMmRNtj4mnZ4t+n/PvMBpL9Jprrom23klDSGPW6B4c\nQgivv/56t8/h8XBKsUqbsv6q4OtBY8Ocd955Sdk3v/nNaE+dOjXau3fvTuppLLFdu3ZF27/rDRs2\nLNq+TnWN6fl80003JfW+/vWvR9v3B12bpfHWelOmTEnKRowYET4KPGoAAAAAAAAAAGoCP9QAAAAA\nAAAAANSElpM+uWSmo6Mj2pq+UiVGIaSuSO6WpO5rOVemEFK3RXeR1branj+vpvM6/vjjkzJ37zrS\nnHHGGd3+u7t/qdzJ3bN1HLSPXDqWo2rKWG9f3dzcdVTTGKpbeAh591Z1mQzhwy7+TaLknl1KX65u\n9aVxu++++6J92223JWU51+O6rY1WRPc9ld64a6rubbp/+ZiqfMrLdC2uX78+W6/J+FxWl2ztfz0T\nQkglKC+//HJSpvup70k5SmeaPmMprbDOCXcn37p1a7TVBd2fV13DNf1sCGUZQBMoSVJK8jN1s6+6\ndlasWJG8VpmZrme/w1SdT01D+8H7WO82fmfR80/HzddRTjJfGk9fpyrBysmgQkhd+L39Ju69Kj/T\nPvI7n46JSiVCSO8tugZKcpWqfen1dE/VPU/l+P5MHiJBZR8aWqAkRa8Tft/QFOPf+973svXuv//+\naC9evDgp031NzyeXmajURr87airoENLvkjt27EjKHnzwwWgvW7Ys2i+99FJST89Cl5Xq3CrNqyM9\nhj6nSpJqfa1njvft3Llzo63SpBDSfVTPPv++peOte6quB6/ne4Ki/ez7vD6jS6ty69nHTdezP6Om\nnc+BRw0AAAAAAAAAQE3ghxoAAAAAAAAAgJpQW+mTupWqO+LMmTOTeueff360NZq0uy2qC5TLkdTd\nSt/XpR3aprsNq6uTSp+8DX2vWbNmJWVr1qwJdWLs2LHd/ru7w6kE4o033kjKZsyYEW3tM++XqhkJ\nepOlxOstXbo02uqG191zHcDlCU2WPvn6qMqrr75aqV5nZ2elejqedcuI1uro/FVJTghphgzPVqOo\n26fLYdR91LMmtAvuGnzKKad0W8+lErqfbtu2LSlzydABSlJcHc+Sa7VLX1SqpO27u7LKuN58882k\nTN3a9Zn8M+ue00Tpk59BSsll+le/+lWP3+uuu+5KXl9++eXRLmW4KT1jk6kqQfJ5mZOnlO6Gui96\n5hqt5y722qaW+RjqeqsqYW5ldM8qZdJTuYHLjHIZPEt3VF2zLqnQ9nxP1Tmk5+7OnTuTejo3/O6p\ndyHN+lX6vnI40D28NPdcBqrf6VQq+/jjjyf1VHLkUiI943Ss/fzU7yf63XH69OnZZ/QMbPp3EyZM\niPbo0aOTeiqxe+GFF5IyPeNVyub3XF3rLofsqzWsITmuvvrqpEylhhMnTkzKdPy1zNeiykm1H/y1\nzl9fA3p/0PH2u6yuTV+nun/rs3sGTe13z2qsz1ia/9qGjxtZnwAAAAAAAAAAWgh+qAEAAAAAAAAA\nqAn8UAMAAAAAAAAAUBMqi5JzaXM/qm5JR1dK9aV6vwsuuCDa06ZNS+qpFiyXnjmEfDq0EFIdoNbz\nZyrpLlWXqu/tejfVIM6ePTsp07TFdSAXD8FRbbDqLUNIx1j7ttSXpbmm/VxKK6xteMyVlStXZtvX\n59J54qnUPRZDk3Btc65ffR3de++9ldov6TVzEKPm0LJly5Zou4ZY14vHnFI2b94cbdfZ6jpynXi7\n4PuTxqfQ+ezac41X4Fr8XAplf69cyk/fW/W9S7GpdI/3+DKahnTVqlVJmer5NTaE7zEa46OJa91j\nUGgskVLcGO/PKnisO12LOsY+70rpS9uFqvHxQkjjfOkd0mPPaJnOba9XKtM2SmOo9xRfz01cV7pv\n7N27N9qeAlfXgJ5bXrc0joquU183ureV4hrpuetjU/os+lx6Ry995zkcaOwyj2+p/e/pxk8//fRo\na196bBj9Tuhx0jRG3pAhQ7L1NPaM9quPYek5pk6dGm2NM3rqqacm9fS70OrVq5Oy7du3h+7wu9La\ntWuj7fFcXnnllW7bOFj0M2k68xDSOab9HEJ6v/GYhYr+nX8P1LTe3u+K3nf87qOUzlYdY30OjcMT\nQrrefI3lYod53Cs9/31daizAHHjUAAAAAAAAAADUBH6oAQAAAAAAAACoCUXpU0k+om5D7nqkdXOS\noBDSlFvu3jd58uRoqxudu3pq+1XTkJZSH+pncdmS4v2Rk1a5FEg/p6Z2C+HDLuVHGh2fkvu8pixT\n9zevq2Pn9RTty55I7pTS86qrvruo5aQ9mjaw6bhrnvZDSbJWNT23Uup/pfS+0HN0zZbm9ooVK7Jl\n6s6pLqsh1G8vOxKU9q7S/rRjx45ou0u8njsll9xcWk8/q0t7rf6dSp+8np6TLgnV80+lIu7GrWk1\nd+/eHZqGy5HOOuusaJfmSekOksPvHDo31PZ9volp0Q8W3Rs9RayuMT2fSmmdc9Lqj0Lb0DH081Pd\n9tsh3brKKHRPcemN7nu6l4WQjnFpX87JKHxP1dd+z9U5k5PChpDKRF2+kwvPcKTvSPqd0FNw69rx\n51R59UMPPRTtTZs2JfX0+53fWXLfOV1KpG0uW7Ys2i5z0/73darnop5bpfVWulNr3/jc1LPQpUB9\nlZ5bz6pf//rXSZl+RpfM6+dQGZj3i/6dy+A03Xzu+2cI6RjoWGlK9BDSueVt6NzQdenrXs9THx/9\nbPpMfr9RqZv/1rFu3brwUfDtBwAAAAAAAACgJvBDDQAAAAAAAABATeCHGgAAAAAAAACAmlAUsaru\n75RTTknKVGfl8Vr0tWoVXVeo+i7XqmmMg5zG2lGNpD9TKU2X1lXbn0nf23WW+lr1pq6LU62ia55d\n13mkUf1lCU0lWErLVop1ktMGe71SCjStW0rjrbr/UopSbcNjcDQZ71fVZZbmqMZceuyxxyq9l6+P\n3sYkgp6ha8L3ZdXOP/roo9k2Fi1aFG2NuRFCOhc0hWgp5k3T8Dg9ut/nzrcQ0hg13oamQdd16bEQ\n9BzTslIcA1+LOkd0T/B6ehfYsGFDUpY773zfHTVqVLRLKeFbld///vfJ6+uvvz7auuf5/qfr6KWX\nXqr0XqVYM6VUpuy9H0bnpc9Zfa33Eo8rlIsp4pTGLRcD0dO+6z3F9w69pzWRffv2RdvjQGg/eTrc\n8ePHR1v3Of8OoWiZj6nOC4994nPoAD72W7dujbanSM7NJ08xrXHoDgcaH2TJkiVJmX6XKH0n0rLS\neit9D9Q2vF/9bnsAj1taQtsvrefc+emvc99bvMzPeI9rdKjQOHMa/yWE8ufV+ff0009H2+dh6blz\nMZdy4xZC9fH28y0370rxbZ1crKrS85Z+m8iBRw0AAAAAAAAAQE3ghxoAAAAAAAAAgJpQlD6pjOXS\nSy/N1nNXJnUB0lRcJSmNu+2p+6i6D3ob6gKn7+vuRepGVWpDU6C5m7i27+5QOalNqY1SyvM64Ong\ncqirvsocnKrpA0uuZiUXNe3bknxKJW3upqzuhdrG1KlTP+qxG4umjzvjjDOi7a6E5557brTvvvvu\nXr1Xzv2+bmuj1dE0iL4PaRrljRs3Ztt44YUXou0usSrRGTNmTK+fs9XQ+ev7Z1WX9T179kTb5Qu6\nP6l7fAndJ0uu1Z56Ul3NtQ135+/fv3+0PbW2prbUu4DvyTofm8irr76avM6l6fX97/LLL492VemT\no/OrdA/yuQYhTJo0Kdo+NjkZdimlutbztah/51KMnHu8S5/0GatK11sZ3TdU+uSpg3Wv9PHR+2BJ\nfpaTUfj5qXteSQaneL2urq5ou4xL17P+3ZFOx66fW+0Q0jPN6U2a6ZJMs6/SVn8Uff2+fj73Fbr3\n6F0whPSs93tLae3k8HuAjqveP3KSQf8bHwNt3++oum61nq+jXFiOENL+GDJkSLR9/pfkXl63O/Co\nAQAAAAAAAACoCfxQAwAAAAAAAABQE4q+cgMGDIi2Z70ZO3ZstD07krpolVym1cXI3QfVjVHx99LX\n+rzu9qkuSx49W1249JnczUnbhq+dAAAMZUlEQVRdH0tuXury7lmQtMxd4/2zHWlK7mbK2rVro62u\nwiGUM1pUqeeucTpPqmZ9cnSMfZ7pHFLaSb7h/OQnP4n2n/70p2y9OXPm9Ljtqu6iSJ8OLbr3uORB\n104pG4Jmz/D9W/e9kSNH9vo5Wxnf+7WfdY/zs0TlDD42ul7UZdbPEq2nY1Nyjy9Jn0pnn46vzxfd\nk48//vhouytwR0dH9rmagPetZtaYOHFi9u+uueaaaN9+++29em8du9L9pl332NIdReW8pcxqpTuL\nopnP3OW9tO/mZJMufdLxVVf8EFIZa29kCnVEx0Qz1LhcSLMX+t1Qx1Glm6UMl/pdxteN7pu+z+Xm\njLN+/fps+7nsMv6dx2WofU2V7DWHiqoZ6o6UDKovOFyfRcfR56/Oe7/z5b7bqjwohBBGjx4dbV+n\n+h1Y90eXYOka279/f/Z5c3eYEFLZYNWMTV6m76dneknq5L+DVMk4hkcNAAAAAAAAAEBN4IcaAAAA\nAAAAAICawA81AAAAAAAAAAA1oRijZvPmzdF+8MEHk7K5c+dGW3W8IaTxa4YNGxZt12apxs019rn0\ndyW9puI6YdWMeewV1bhpe66t0/d2vbK2qTph17TlUvyFkGr36kAuXac/96pVq6I9b968pCyXTruk\ntyxpvLVvSzrrUko1TR3sOt4TTzyx2zZy86wdePbZZ6Nd6tdSanaoF1W18qV1qvu5t6H7o6dKbTLa\nX6pZDiGEhQsXRnv8+PHRLp1pHhtO90Ydw1JqZY2L4TFqSvtpTrftc0JjYfhY6/OqFlvjG4XwYQ16\n0/C+1fvUj370o2j7OtK7VFV8fPS9q8aJgw/Q9M/btm1Lyt57771oV72zaD2/h+p+Woq1oLbGBwzh\nw+tKaVK8jgPo94ZSjJp169ZF2/dAjUuoY1yKZaPxM/x7TWmMtQ1dl/5eO3bsCDn0bG36vqn0Zn+q\nYxrvVkb7zFPK62udlx5HS2Nl+fiUUm3nnqPKv7c6eNQAAAAAAAAAANQEfqgBAAAAAAAAAKgJRemT\nSoKee+65pGzx4sXR9rTS48aNi/aECRO6/fcQ0pTH6mIaQupOre27a5M+o7o3Pv3000m9lStXRnvv\n3r1Jmbou6ntNmzYtqXfRRRdF29NQaxtqb9iwIamn7Xd1dSVljz/+eKgT7tKZQ+VDnpJW3UDV5dSl\nROr6qX/j461/52VVXSNnzJgR7U2bNiVlp512WrfP0fT0sSV27doVbXXlLUk2dKxLad7dZTzn+thO\nLr6HA3UT97VYGi9FUw77OKqL9759+3rziC3Pnj17kte/+c1voq2pVP0sUXd+PSNDSM84bd/PYN27\ndTw9paau4ZJcWGUenZ2dST3d/1esWJGU6ZmpcgGfYzof2wGdCz/4wQ+i7eOjkjadM57aWfFzMOcO\n7nKLdhuDA+Rk9iGk0n2XGeXSnru0Jtf/fr9S6YCPjbahkhlP+65reOTIkUlZE6Rt/hlyqW29z197\n7bVol8ZH9zyVRIWQ7pU6ViXJqKNl+uwu1VJ5iH9GvWPr85bkd02gqbKWptMbCROkNHtlAwAAAAAA\nAAC0EPxQAwAAAAAAAABQE/ihBgAAAAAAAACgJhRj1CiuJVONuccgWL58ebd2KRVX1bSR/hz62nW9\nvUFTiXkMmYcffrjH7fVEg1c3vZ7GQCil1tYYJlV1slXHuzSmpflUQlOerlmzJinLfc5S2sumo/2g\nmniNIxVCqr+ePXt2tD1eVG/eV2NkwMGjunePNVR1H9K54OtU16KncWxX9MzUvvNzZvr06dH22DPa\nlxrLphTrSWMoeL1cjIcQ0vgH2p6vRW3D0wpr/Br9/KVzvB3Q9Lt65+jfv39ST+NpXH311dFesGBB\n5ffKxeDzNduu61TXhKY+9jJPmaz9movPFkLar2r72tM14HcZfY7SvVnrDRo0KFvWFLSvNYaTj6OO\nnY+P9qGOo/eXtq+Uvht5LC4dc50//ry6x+oeGkIaR0lj9/neCwDNoHk7NwAAAAAAAABAi8IPNQAA\nAAAAAAAANaGy9OlQ0Gruzq32vIeanKus90PJ9V3dSt2NX1GXU/0bd1PN/Y3/XQl1YfWUm4pKBnAr\n/YCnnnoq2l/60pey9e6+++5oT5kyJVuvNGa5lKRw8Gga5XPOOScpqzrXdd37WtR1u3Xr1t48YqPR\neT9ixIikbM6cOdF2eaHKVVSOWZKIallJLur7vbrj61r01ND6/KV04iWZVbuhY7Jw4cJof/vb307q\n6fjcfvvt0S5Jn3qbnnvv3r2FJ24uuld5mmSd66tXr07KVMak+5+nOdfxULmLn2kl6VPunPQx1PY7\nOjqSMl3P+uytdK/1ftCxGz58eLRdcqQyft9vPU36ATxVu/Z16W6oz+h7nr7WZx88eHBST9v00BK6\nx+o5zv4K0EzwqAEAAAAAAAAAqAn8UAMAAAAAAAAAUBMOq/QJWgt17yxJVPbv3x/tu+66Kym75ZZb\noq3uwe5WWspMksPdfnMZwI4++uik3jPPPBNtz3SRyzCG9OkDbrzxxmiXpE/qhlyi5HatY3goMrrB\n/1GZg8sLS9l5lKpZYjZt2tTDp2svfC/U8Shl5NJ9zbOGaBuaHcrfS/fa0n6quLRD50tv51I7c/PN\nN0f7G9/4RlKm4+qSjRx+fub63aU3moms6eg5r2vCJSjbtm2L9ssvv5wt07uNSwN9bR6gJ3eK3Bi6\nxEdlMp5BbMCAAdHWsW6ldenPqnvRyJEjo+1yJr2jer+rZEj7s2pWNK+n688lwTkZqn8ufa8tW7Yk\nZQMHDoy2ZodC+gTQTPCoAQAAAAAAAACoCfxQAwAAAAAAAABQE/ihBgAAAAAAAACgJhCjBrJoWl3V\n1rqeVuvdcccdSZm/zqF63ZztlLTVWuZpwVVD7rp/1Sir5reUxrudyM2JEFJttuvjc7juW+NukJK7\n79AYNaWYUCUdfW6teJlr7NuVXAwtj2mhcSZmzZqVlGm8i507d0bbYzJoGxonwcdQ15jHr9HX/fr1\ni7bvmdqGxsEIgdhSVdA0656KV2N96dh77AsdAx/jt99+O9oeg0Vpp7HKxag54YQTknoaX2vjxo1J\nmZ5d2p7GDQkhjRGlf1OKUVOKF6W2jm0IISxdujTa48ePzz5H6V5VZ0rpuYcOHRptjUkTQtrvvlfm\n2tD+CiE9J/W88zuM3jc93bvei/S9tm/fHnLs3r07ea1rWMe/ndYvQDuBRw0AAAAAAAAAQE3ghxoA\nAAAAAAAAgJqA9AmyqOunutt6SshDkRYw59p7KCilHd21a1fyOpeCkdSHH6Au9t5X7irc0/YcXHn7\njlIK6EGDBkW7JH0qpU/X9l0KAGlfqpwwhBBefPHFaE+fPj0pGzduXLQ7Ojqi7S726hKv67Ikc/N5\nkFvrPtY6vr4nIF/8aLQ/33jjjaRs2LBh0dY5U5I+OSqdGD16dLaey0WaTE76NGrUqKTea6+9Fm2X\npeXkZr4+qq6j0h0oV+Z768qVK6Ptn0Vlxa0qfSql5/Y9UNEx0LTqIYSwaNGiaE+aNCnaEydOTOrp\nPNH91aVJxx13XLRd3qayK71TrlmzJlvP76+675ekjFCmdLcBqBN41AAAAAAAAAAA1AR+qAEAAAAA\nAAAAqAn8UAMAAAAAAAAAUBOIUQNZbrvttmhr/IKurq6kXivrOz3ezm9/+9toa6yOO++887A9U6tw\nyy23JK+/+93vRvu6666r1MYNN9yQvNb+f/zxx3v/cFBk8eLF0XbN/tNPPx3tUpwgLdO0sCGksTU8\n/TSke6bHvnjmmWeireMUQpr+WlM3z5gxI1tPY1V4jBqNoeBxuNavXx9tjZ3iqWQ1noLPJWLU9Iyb\nbropef3LX/4y2qtXr452KWaar9n58+dH++abb472hg0bknr33Xdfzx62hdH1p2tg+fLlSb3nn38+\n2p7Wueq9p2r8PY3r5TFk9L21DV9fnZ2d0X7iiSeSslKsvlZFzyr9fJrKPoT0DPI732OPPRbtJUuW\ndGuHEMKQIUOi3a9fv2j7/q3j43GfdHw0zo3X02e85557krLTTz892s8++2y0fX42jUMRV0nb6G2M\nmlzdVv4eBPUGjxoAAAAAAAAAgJrADzUAAAAAAAAAADXhKNy1AAAAAAAAAADqAR41AAAAAAAAAAA1\ngR9qAAAAAAAAAABqAj/UAAAAAAAAAADUBH6oAQAAAAAAAACoCfxQAwAAAAAAAABQE/ihBgAAAAAA\nAACgJvwP0+ysEdK1AAIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2331c520b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GEceYdeOQyLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**c)** Compare the visual results to those of the DAE in Task 2.3. Also compare the loss values of the test set for the DAE and SAE. How can you explain the difference?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "nqkTQEdDQyLx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is a little bit of a difference between the loss values of the DAE and the one from the SAE. The SAE has slightly higher loss values but in our opinion does generate better representations of the original picture. For example the flipflop is clearly a flipflop now instead of somewhat of a blur with the DAE. The differences come from the way that both encoders generate their 'corrupted' data of the original data. For the DEA the 'corrupted' data is generated somewhat random and beforehand. This means that any possbible 'corrupted' version has a change to exists, every pixel of the image can be changed. The sparse autoencoder imposes sparcity on hidden layers, in our case on the last dense layer of the encoder. This allowes the autoencoder to learn useful structures of the data. The sparse autoencoder applies penalties on layers. In this case on the activity layer and this penalty is then incorperated into the loss function, thus explaining the higher loss values. "
      ]
    },
    {
      "metadata": {
        "id": "qvfnidDrQyLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Task 2.5: Comparison\n",
        "Obtain 128-dimensional neural code representations of the last five classes of the Fashion-MNIST dataset (the *retrieval set*: `x_train_r`) from the following models/layers:\n",
        "1. The last dense hidden layer (before the output layer) of the MLP you trained in Task 2.1\n",
        "2. The last dense hidden layer (before the output layer) of the CNN you trained in Task 2.2\n",
        "3. The center layer/code of the DAE you trained in Task 2.3\n",
        "4. The center layer/code of the SAE you trained in Task 2.4\n",
        "5. A PCA-transformation"
      ]
    },
    {
      "metadata": {
        "id": "1Lso3um-QyLz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# additional imports\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3t8q8fuvQyL0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "2e031eb5-ba56-4343-f829-05d14d486b60",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520943729555,
          "user_tz": -60,
          "elapsed": 37073,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load the previously trained and saved models\n",
        "mlp = load_model(\"mlp_fashionmnist_l.h5\")\n",
        "cnn = load_model(\"cnn_fashionmnist_l.h5\")\n",
        "dae = load_model(\"dae_fashionmnist_l.h5\")\n",
        "sae = load_model(\"sae_fashionmnist_l.h5\")\n",
        "# NOTE: change the name \"neural codes\" if the layer from which you wish to retrieve neural codes has a different name\n",
        "mlp_nc = Model(inputs=mlp.input, outputs=mlp.get_layer(\"neural_codes\").output)\n",
        "cnn_nc = Model(inputs=cnn.input, outputs=cnn.get_layer(\"neural_codes\").output)\n",
        "dae_nc = Model(inputs=dae.input, outputs=dae.get_layer(\"neural_codes\").output)\n",
        "sae_nc = Model(inputs=sae.input, outputs=sae.get_layer(\"neural_codes\").output)\n",
        "\n",
        "# obtain flat representations of the data\n",
        "x_train_r_flat = x_train_r.reshape((x_train_r.shape[0], -1))\n",
        "x_test_r_flat = x_test_r.reshape((x_test_r.shape[0], -1))\n",
        "\n",
        "# train PCA on the retrieval set\n",
        "pca = PCA(n_components=128)\n",
        "pca.fit(x_train_r_flat)\n",
        "\n",
        "# obtain 128-dimensional representations\n",
        "nc_mlp_train = mlp_nc.predict(x_train_r)\n",
        "nc_mlp_test = mlp_nc.predict(x_test_r)\n",
        "nc_cnn_train = cnn_nc.predict(x_train_r)\n",
        "nc_cnn_test = cnn_nc.predict(x_test_r)\n",
        "nc_dae_train = dae_nc.predict(x_train_r)\n",
        "nc_dae_test = dae_nc.predict(x_test_r)\n",
        "nc_sae_train = sae_nc.predict(x_train_r)\n",
        "nc_sae_test = sae_nc.predict(x_test_r)\n",
        "nc_pca_train = pca.transform(x_train_r_flat)\n",
        "nc_pca_test = pca.transform(x_test_r_flat)\n",
        "\n",
        "# print the shapes to confirm all features are 128-dimensional\n",
        "print(nc_mlp_train.shape)\n",
        "print(nc_mlp_test.shape)\n",
        "print(nc_cnn_train.shape)\n",
        "print(nc_cnn_test.shape)\n",
        "print(nc_dae_train.shape)\n",
        "print(nc_dae_test.shape)\n",
        "print(nc_sae_train.shape)\n",
        "print(nc_sae_test.shape)\n",
        "print(nc_pca_train.shape)\n",
        "print(nc_pca_test.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 128)\n",
            "(5000, 128)\n",
            "(30000, 128)\n",
            "(5000, 128)\n",
            "(30000, 128)\n",
            "(5000, 128)\n",
            "(30000, 128)\n",
            "(5000, 128)\n",
            "(30000, 128)\n",
            "(5000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IK-f25xGQyL1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**a)** Evaluate the retrieval task as described in Question 1 on the last 5 classes (the retrieval set) of the Fashion-MNIST dataset, for the five data representations given above. Use query images from the test set and retrieve images from the training set only. Print the five resulting retrieval scores (between 0 and 5).\n",
        "\n",
        "*HINT: you can use* `y_train_digits_r` *and* `y_test_digits_r` *to obtain digit encodings (as opposed to one-hot encodings) of the data labels.*"
      ]
    },
    {
      "metadata": {
        "id": "UaqLBkrffI3_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f46cc323-fa5b-4af1-8cf6-caa8462d5524",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520946690706,
          "user_tz": -60,
          "elapsed": 2293,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install itertools"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting itertools\n",
            "\u001b[31m  Could not find a version that satisfies the requirement itertools (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for itertools\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Epn95_TQyL2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ea1f35dc-d95f-4bb4-f650-f6cbc9f10a37",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520947419785,
          "user_tz": -60,
          "elapsed": 5551,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# make random selection of n query images/indices, the same for all experiments\n",
        "n = 200\n",
        "n_examples = 5000  # the retrieval test set has 5000 images\n",
        "indices = np.random.choice(range(n_examples), size=n, replace=False)\n",
        "scores=[0,0,0,0,0]\n",
        "p = 0\n",
        "#print(y_train_digits_r)\n",
        "representations = [\n",
        "    (nc_mlp_train, nc_mlp_test),\n",
        "    (nc_cnn_train, nc_cnn_test),\n",
        "    (nc_dae_train, nc_dae_test),\n",
        "    (nc_sae_train, nc_sae_test),\n",
        "    (nc_pca_train, nc_pca_test),\n",
        "]\n",
        "for (nc_train, nc_test) in representations:\n",
        "    # === SOLUTION: ===\n",
        "    # insert code here\n",
        "    neigh = NearestNeighbors(n_neighbors=5, p=2)\n",
        "    neigh.fit(nc_train)\n",
        "    QI = nc_test[indices]\n",
        "    nn = neigh.kneighbors(QI)\n",
        "    for i in nn[1]:\n",
        "      for k, l  in zip(i[:-1], i[1:]):\n",
        "        #print(k, l)\n",
        "        label = y_train[k]\n",
        "        label_digit = y_train_digits[k]\n",
        "        label_class_j = classes[label_digit]\n",
        "        #print(label_class)\n",
        "        label = y_train[l]\n",
        "        label_digit = y_train_digits[l]\n",
        "        label_class_k = classes[label_digit]\n",
        "        #print(label_class)\n",
        "        if label_class_j == label_class_k:\n",
        "          scores[p] +=1\n",
        "    p += 1\n",
        "for s in scores:\n",
        "  q = s/200\n",
        "  print(q)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4\n",
            "0.4\n",
            "0.485\n",
            "0.335\n",
            "0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xTSsSYOuQyL4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**b)** Compare the \"baseline\" PCA-transformed data with the other methods. Is PCA a suitable method to obtain representations for image retrieval in this situation? Why do you think so? Would you expect a similar conclusion for the Caltech101 dataset from Question 1?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "S5RwOwc-QyL4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We think that PCA is a suitable method to obtain representations for image retrieval. Out of all the three different models it obtains the best score. Ofcourse all of them don't achieve a spectecular score (most are less than 0.5). Since it is quite random for them to select items from the training set based on images out of the test set. However based on the scores we see that PCA does not only perform as well it performs even better then our trained models. We think this is due to the fact that there are quite a large differences between the different classes in the training set of which the images are chosen. The also do not really compare to the classes in the test set. \n",
        "\n",
        "We expect the same result for the Caltech101 dataset since here also there are quite some different classes. However it could play a factor that in those pictures there is color as well which is not present in the FASHION-MINST data set."
      ]
    },
    {
      "metadata": {
        "id": "RmsLjqg0QyL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "Observe the difference between encodings from the DAE and SAE."
      ]
    },
    {
      "metadata": {
        "id": "ErYpJnX8QyL6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1225
        },
        "outputId": "2b1d2d7a-c5eb-47b8-8ded-386a44b80ebf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520947528325,
          "user_tz": -60,
          "elapsed": 539,
          "user": {
            "displayName": "Thijs Ledeboer",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112614377174306060047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Mean activation for DAE encodings:\", np.mean(nc_dae_train))\n",
        "print(\"Mean activation for SAE encodings:\", np.mean(nc_sae_train))\n",
        "\n",
        "index = 9000  # try a few indices here\n",
        "print(\"DAE encoding example:\")\n",
        "print(nc_dae_train[index])\n",
        "print(\"SAE encoding example:\")\n",
        "print(nc_sae_train[index])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean activation for DAE encodings: 3.442056\n",
            "Mean activation for SAE encodings: -0.00017243795\n",
            "DAE encoding example:\n",
            "[ 2.83382630e+00 -9.98998106e-01 -9.95019734e-01 -7.43273079e-01\n",
            " -9.42138851e-01 -9.99733448e-01 -9.98841822e-01  2.29535084e+01\n",
            "  9.52881241e+00  1.87907219e+00 -1.00000000e+00  1.34943123e+01\n",
            "  9.93903828e+00 -9.99506056e-01  6.09373856e+00 -9.98469472e-01\n",
            " -9.99911487e-01  1.11554861e+01 -9.65158641e-01 -9.91949856e-01\n",
            "  2.97600722e+00 -9.99993503e-01 -9.69555378e-01 -9.99689400e-01\n",
            " -5.69364727e-01  1.39413226e+00  6.23614550e+00  8.58841133e+00\n",
            " -9.99770880e-01 -9.99563694e-01  1.06557169e+01  5.51328135e+00\n",
            " -9.92507696e-01  4.86196578e-03 -9.85668480e-01  2.74740434e+00\n",
            "  6.03305674e+00  5.08033371e+00 -9.99938905e-01 -9.99669135e-01\n",
            " -5.35120487e-01  2.18159959e-01 -8.84691238e-01 -9.94392157e-01\n",
            " -9.42477942e-01 -9.99991834e-01 -4.34415936e-01 -9.99806225e-01\n",
            " -9.88536239e-01  5.49327326e+00  1.54768925e+01 -1.93113625e-01\n",
            "  8.17384815e+00  8.09881115e+00 -9.98520672e-01  6.62300158e+00\n",
            " -9.99415278e-01 -9.98655796e-01 -9.50842559e-01 -9.99310851e-01\n",
            "  4.42731476e+00 -9.98738527e-01 -9.99933660e-01 -9.95052516e-01\n",
            " -9.92560148e-01  2.32795048e+01 -9.99730587e-01 -9.99999046e-01\n",
            " -9.99999881e-01 -9.65131104e-01 -9.99477029e-01  4.81537342e+00\n",
            "  1.52635127e-01 -9.13735569e-01  4.94364405e+00 -8.81808281e-01\n",
            " -9.99999285e-01 -9.05386269e-01  1.32386274e+01 -9.99264896e-01\n",
            "  4.95647097e+00 -9.99927819e-01  1.58322978e+00 -9.86997843e-01\n",
            " -9.95062888e-01 -9.83445525e-01  6.49302387e+00 -9.72766876e-01\n",
            " -9.89697635e-01  5.15856457e+00 -5.66903472e-01 -6.29431605e-01\n",
            " -9.97648180e-01 -9.92548168e-01  2.19916010e+00 -9.99902427e-01\n",
            "  4.86065149e+00 -9.87117767e-01 -9.99321103e-01 -9.99999344e-01\n",
            " -9.99970973e-01  1.06331415e+01 -9.40899312e-01 -8.62271488e-01\n",
            " -9.98503089e-01  3.00089645e+00 -9.29831862e-01 -9.84711409e-01\n",
            "  3.09602189e+00 -9.92254972e-01 -9.99992073e-01  3.16996241e+00\n",
            "  1.19396305e+01 -9.86107647e-01 -9.82469141e-01  5.86306334e+00\n",
            "  2.20834885e+01 -9.99998450e-01 -8.42877209e-01  5.99725103e+00\n",
            " -8.49547088e-01  7.98944521e+00  5.27801275e+00 -9.94208097e-01\n",
            " -9.85817850e-01 -4.43912089e-01 -9.94620442e-01 -9.99991596e-01]\n",
            "SAE encoding example:\n",
            "[ 4.82957205e-03 -7.56144524e-04  1.84022263e-03  1.77976256e-03\n",
            " -5.31497002e-02 -2.80093551e-02 -4.22710180e-03 -1.25560164e-02\n",
            "  3.18370480e-03 -5.41925430e-04 -9.44942236e-03 -2.12895870e-03\n",
            " -1.17981434e-03 -1.97070837e-03  6.52184524e-03 -2.19184160e-03\n",
            " -5.11753559e-03  6.49241637e-03 -3.43596935e-03 -2.29418278e-04\n",
            " -3.88472676e-02  1.71296112e-02  8.40867695e-04 -7.73429871e-03\n",
            " -4.37444448e-03  9.88237467e-03 -7.11721182e-03 -1.06829405e-03\n",
            " -2.21991539e-03 -1.06365681e-02  9.18997824e-03  1.93315372e-03\n",
            "  1.20444950e-02  2.03417963e-03 -7.01189041e-04  5.16152475e-03\n",
            " -2.21729875e-02  5.90095297e-04  9.26297158e-03  9.42356419e-04\n",
            " -7.19499588e-03 -4.35262918e-03  1.49717908e-02 -6.09165430e-03\n",
            "  9.53650195e-03  1.94671322e-02 -3.68779898e-03  7.96385854e-02\n",
            " -3.37916613e-03  5.35902567e-03 -7.09789991e-03 -6.72340393e-03\n",
            "  9.86150373e-03  3.22664902e-03 -1.51474476e-02 -9.87350941e-03\n",
            "  3.55591439e-03 -4.22215462e-03 -3.68356705e-04 -1.22531056e-02\n",
            "  3.65163176e-03 -1.72257423e-05 -1.23440623e-02 -4.14371490e-04\n",
            "  1.32176820e-02 -7.45016336e-03 -9.26560163e-03 -3.18217278e-03\n",
            "  1.49735902e-03  3.67248920e-03 -1.00088120e-02  5.45298075e-03\n",
            " -2.57861614e-03 -8.20088387e-03 -2.55566835e-03 -8.94069672e-03\n",
            " -1.01387501e-03  1.07558258e-02 -1.07115507e-03 -1.11787915e-02\n",
            "  1.58928111e-02  2.33843457e-03  1.37013886e-02 -3.55839729e-05\n",
            " -1.05369091e-03  8.33447836e-03 -2.50577927e-04  1.57880224e-03\n",
            "  2.34461180e-03  1.76401064e-03 -2.53158808e-03 -2.67243385e-03\n",
            " -2.31611729e-03 -1.35967731e-02  2.70098029e-03 -1.15894079e-02\n",
            " -7.24059343e-03  5.87955536e-03  1.32143288e-03  1.75826380e-03\n",
            " -1.22165680e-03 -1.29901171e-02  7.11748609e-03 -1.51687860e-03\n",
            " -1.81654096e-02 -4.83423471e-03  3.17255175e-03  3.51532851e-03\n",
            "  3.51687800e-03  8.27249838e-04  4.10311408e-02 -1.22990012e-02\n",
            "  1.29784993e-03  8.33893940e-03 -1.28269196e-04  2.21712748e-03\n",
            "  1.59065556e-02  5.80255874e-03 -1.23119354e-03 -9.87178087e-03\n",
            " -3.01561356e-02  3.10959737e-03  5.23533439e-03  4.65912744e-04\n",
            " -5.50162792e-03  3.45518813e-03 -2.90197134e-03  1.22956140e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l1X_VGidQyL7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**c)** Discuss the difference in encodings between the two autoencoders (denoising and sparse). Also discuss the difference in retrieval performance for these encodings. How would you explain this difference?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "8de_dlzBQyL8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is quite a difference between the different mean activations. It seems that in almost every case the DAE encoding is way more positive than the SAE encoding. We think that it is due to the fact that the DAE encoding looks at a lot of different aspects of the image. It tries to find what are key features for certain classes. The SEA encoding tries to find hidden features in the data. We expect that because of that the encoding is a lot less positive "
      ]
    },
    {
      "metadata": {
        "id": "8Pi-C1IcQyL8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "**d)** What is the best performing method you found in part a)? Describe what advantage you believe this method has over the others.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "metadata": {
        "id": "43w8ug6LQyL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*=== write your answer here ===*"
      ]
    }
  ]
}