{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Thijs\\Anaconda3\\envs\\Python35\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13) #TODO Check if this is used for sgd\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors as nn\n",
    "from matplotlib import pylab\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT Modify the lines in this cell\n",
    "path = 'alice.txt'\n",
    "corpus = open(path).readlines()[0:700]\n",
    "\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Is this something they need to change?\n",
    "dim = 100\n",
    "window_size = 2 #use this window size for Skipgram, CBOW, and the model with the additional hidden layer\n",
    "window_size_corpus = 4 #use this window size for the co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### Co-occurrence Matrix\n",
    "Use the provided code to load the \"Alice in Wonderland\" text document. \n",
    "1. Implement the word-word co-occurrence matrix for “Alice in Wonderland”\n",
    "2. Normalize the words such that every value lies within a range of 0 and 1\n",
    "3. Compute the cosine distance between the given words:\n",
    "    - Alice \n",
    "    - Dinah\n",
    "    - Rabbit\n",
    "4. List the 5 closest words to 'Alice'. Discuss the results.\n",
    "5. Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.44444444,  0.48148148, ...,  0.03703704,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.44444444,  0.        ,  0.07407407, ...,  0.03703704,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.48148148,  0.07407407,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.03703704,  0.03703704,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create co-occurrence matrix\n",
    "#print(tokenizer)\n",
    "#print(corpus)\n",
    "#print(nb_samples)\n",
    "#print(V)\n",
    "#print(\"\\n\")\n",
    "\n",
    "def create_co_occurrence(crps, win_size, voc_size):\n",
    "    # Discuss -1 with Thijs\n",
    "    co_occurrence_mat = np.zeros((voc_size-1,voc_size-1), int)\n",
    "    for sentence in crps:\n",
    "        # Sliding window inside of sentence\n",
    "        for i, center_word in enumerate(sentence):\n",
    "            i_min = max(0, i - win_size + 1)\n",
    "            i_max = min(len(sentence), i + win_size)\n",
    "            window = sentence[i_min: i_max]\n",
    "            #print(\"Window:\", window)\n",
    "            \n",
    "            # Increment co occurence of words in sliding window\n",
    "            for j in range(i_min, i_max):\n",
    "                if i != j:\n",
    "                    co_word = sentence[j]\n",
    "                    co_occurrence_mat[center_word-1, co_word-1] += 1\n",
    "    \n",
    "    np.amax(co_occurrence_mat)\n",
    "    \n",
    "    return co_occurrence_mat\n",
    "\n",
    "co_occurence = create_co_occurrence(corpus, window_size, V)\n",
    "\n",
    "#Normalize\n",
    "co_occurence = co_occurence / np.amax(co_occurence)\n",
    "co_occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eagerly': 371, 'asked': 1050, 'thing': 89, 'make': 212, 'please': 217, 'australia': 645, 'house': 156, 'piece': 1059, 'seemed': 113, 'grow': 480, 'first': 104, 'worse': 879, 'direction': 1162, 'fall': 257, 'live': 862, 'candle': 347, 'their': 180, 'gravely': 1061, 'cold': 984, 'paused': 1033, 'hide': 1031, 'picking': 593, 'suddenly': 175, 'capital': 284, 'fountains': 693, 'how': 38, 'dears': 487, 'est': 918, 'waters': 849, 'might': 161, 'speed': 878, 'yourself': 494, 'ate': 770, 'head': 189, 'say': 83, 'five': 828, 'hurriedly': 1011, 'met': 1087, 'pictures': 246, 'deal': 357, 'theirs': 1077, 'were': 65, 'important': 986, 'bend': 1101, 'dream': 657, 'sort': 179, 'ferrets': 578, 'skurried': 816, 'leave': 472, 'chapter': 242, 'northumbria': 556, 'trial': 571, 'swim': 1156, 'called': 199, 'mouse': 25, 'play': 865, 'knot': 1103, 'french': 531, 'dinah': 87, 'field': 604, 'toys': 864, 'ever': 119, 'hopeless': 801, 'w': 1170, 'dark': 305, 'shedding': 803, 'hippopotamus': 906, 'oh': 51, 'looking': 203, 'further': 742, 'race': 202, 'somebody': 307, 'fanning': 818, 'fancy': 321, 'understand': 530, 'went': 52, 'pour': 848, 'taste': 461, 'to': 3, 'poker': 716, 'declare': 880, 'temper': 1120, 'kid': 231, 'box': 350, 'absurd': 1067, 'climb': 749, 'pointing': 1051, 'lessons': 313, 'finger': 341, 'by': 71, 'tail': 285, 'it': 7, 'ahem': 985, 'throat': 1137, 'minutes': 467, 'hardly': 764, 'this': 28, 'frowning': 998, 'sound': 641, 'burning': 602, 'love': 799, 'talking': 182, 'ten': 738, 'finished': 344, 'thump': 431, 'walking': 430, 'name': 319, 'belongs': 952, 'high': 168, 'open': 678, 'melancholy': 559, 'growled': 1109, 'suit': 1136, 'exact': 1037, 'done': 516, 'nervous': 743, 'easy': 1040, 'then': 79, 'history': 367, 'fell': 209, 'fitted': 684, 'so': 30, 'grave': 1068, 'water': 365, 'canterbury': 1005, 'bill': 1149, 'scale': 851, 'adoption': 1026, 'certainly': 456, 'where': 1151, 'improve': 846, 'mice': 325, 'is': 33, 'book': 205, 'funny': 418, 'not': 29, 'at': 34, 'duck': 374, 'natural': 391, 'times': 359, 'ugh': 996, 'means': 1007, 'took': 139, 'antipathies': 639, 'too': 155, 'conversation': 944, 'patriotic': 1003, 'came': 163, 'burn': 717, 'stigand': 1002, 'pardon': 288, 'bats': 269, 'pope': 990, 'began': 75, 'afraid': 268, 'noticed': 306, 'comfits': 566, 'lodging': 897, 'bright': 335, 'printed': 702, 'zealand': 644, 'into': 72, 'plenty': 612, 'she': 4, 'severely': 475, 'sharply': 471, 'patted': 1080, 'later': 724, 'mistake': 1164, 'enough': 275, 'looked': 129, 'children': 274, 'chorus': 565, 'subject': 539, 'alice': 11, 'magpie': 1132, 'dripping': 969, 'paws': 536, 'call': 1086, 'acceptance': 1063, 'nearer': 904, 'look': 154, 'hear': 296, 'slippery': 751, 'got': 118, 'his': 151, 'conclusion': 887, 'largest': 780, 'moved': 1142, 'suppose': 527, 'game': 759, 'condemn': 1096, 'bird': 1130, 'daughter': 1118, 'talk': 237, 'just': 141, 'mean': 1106, 'short': 1065, 'playing': 761, 'undo': 1104, 'messages': 582, 'locked': 671, 'draggled': 966, 'longitude': 417, 'ventured': 725, 'idea': 260, 'digging': 893, 'work': 777, 'both': 1088, 'ones': 1078, 'wonder': 103, 'knows': 826, 'himself': 811, 'actually': 600, 'lap': 840, 'tiny': 445, 'rate': 270, 'sometimes': 427, 'beautifully': 457, 'vulgar': 943, 'away': 165, 'station': 899, 'decided': 746, 'answer': 326, 'night': 324, 'splendidly': 809, 'crowded': 289, 'me': 42, 'why': 132, 'am': 160, 'impatiently': 1114, 'smaller': 767, 'london': 837, 'great': 117, 'close': 295, 'always': 369, 'that': 13, 'we': 239, 'somehow': 884, 'perhaps': 265, 'something': 286, 'doesn': 173, 'seldom': 754, 'ma': 320, 'farmer': 953, 'happens': 481, 'being': 362, 'was': 9, 'miss': 424, 'fancying': 1176, 'about': 40, 'lest': 1174, 'fixed': 983, 'moment': 131, 'waistcoat': 393, 'thinking': 823, 'remarkable': 390, 'won': 172, 'marmalade': 620, 'lovely': 740, 'conqueror': 532, 'dropped': 358, 'advice': 753, 'never': 115, 'beginning': 584, 'these': 881, 'adjourn': 1024, 'curiosity': 603, 'knowledge': 413, 'worth': 388, 'simply': 1071, 'caused': 568, 'glass': 222, 'earnestly': 658, 'i': 6, 'attending': 1098, 'roof': 439, 'solemnly': 560, 'alone': 515, 'gallons': 804, 'dreamy': 654, 'flavour': 727, 'hate': 544, 'wondered': 599, 'doors': 440, 'leaders': 992, 'move': 1022, 'catch': 425, 'ii': 778, 'licking': 936, 'hadn': 526, 'hastily': 279, 'sure': 136, 'felt': 184, 'bad': 520, 'energetic': 1027, 'neck': 699, 'opening': 779, 'beg': 195, 'offer': 1014, 'yes': 415, 'miles': 407, 'darkness': 817, 'side': 441, 'doth': 513, 'go': 82, 'bleeds': 721, 'cried': 124, 'positively': 980, 'curiouser': 484, 'crossly': 1006, 'neatly': 854, 'world': 301, 'all': 22, 'itself': 297, 'speaking': 529, 'ears': 436, 'birds': 200, 'little': 24, 'breath': 1094, 'from': 256, 'quite': 78, 'saying': 183, 'placed': 1039, 'says': 541, 'wept': 900, 'lonely': 1144, 'silence': 550, 'c': 1083, 'changed': 235, 'shelves': 399, 'size': 465, 'spades': 896, 'pegs': 616, 'directions': 795, 'flowers': 691, 'be': 20, 'pattering': 496, 'swimming': 528, 'soon': 76, 'three': 331, 't': 35, 'remarking': 1135, 'law': 1089, 'cheerfully': 852, 'sensation': 1131, 'sea': 523, 'locks': 677, 'creatures': 963, 'upon': 142, 'conquest': 995, 'drowned': 902, 'washing': 937, 'animal': 924, 'eyes': 176, 'pink': 595, 'they': 39, 'sulky': 976, 'if': 32, 'who': 96, 'ada': 824, 'surprised': 277, 'followed': 755, 'crown': 1015, 'trotting': 497, 'mine': 507, 'roast': 733, 'best': 225, 'geography': 836, 'wind': 666, 'rather': 181, 'hedge': 607, 'mary': 580, 'burst': 869, 'shall': 92, 'd': 198, 'six': 830, 'fright': 923, 'circle': 1036, 'shan': 784, 'cut': 718, 'alas': 332, 'bathing': 891, 'ran': 207, 'trying': 187, 'table': 120, 'managed': 403, 'feathers': 967, 'hot': 249, 'sleepy': 384, 'softly': 960, 'shape': 1038, 'shore': 543, 'gently': 859, 'neat': 1167, 'altogether': 468, 'general': 886, 'morcar': 553, 'able': 785, 'maps': 614, 'tried': 211, 'wrapping': 1133, 'time': 66, 'longed': 688, 'belong': 676, 'nicely': 934, 'wander': 689, 'reaching': 806, 'tongue': 1121, 'against': 476, 'presently': 637, 'currants': 766, 'poky': 863, 'ringlets': 506, 'and': 2, 'her': 14, 'worm': 1009, 'goes': 825, 'falling': 396, 'elegant': 1064, 'drop': 623, 'doorway': 694, 'pet': 1129, 'pretend': 763, 'lit': 668, 'lock': 682, 'after': 102, 'hair': 505, 'than': 223, 'curtsey': 646, 'asking': 423, 'beds': 690, 'accustomed': 993, 'older': 977, 'finds': 1166, 'other': 221, 'such': 74, 'nice': 215, 'peeped': 587, 'family': 940, 'earls': 554, 'dull': 774, 'hurrying': 665, 'makes': 479, 'knowing': 979, 'girl': 422, 'middle': 444, 'submitted': 991, 'what': 44, 'sad': 569, 'croquet': 760, 'pine': 731, 'hoped': 1181, 'ought': 299, 'indeed': 190, 'consultation': 972, 'remember': 219, 'swam': 236, 'stop': 495, 'reach': 469, 'easily': 1108, 'the': 1, 'smiling': 860, 'throw': 950, 'hoarse': 843, 'dog': 945, 'burnt': 706, 'young': 1122, 'hurry': 339, 'houses': 898, 'rabbit': 63, 'get': 67, 'sides': 613, 'anything': 213, 'possibly': 747, 'those': 271, 'cheated': 758, 'o': 366, 'conduct': 1016, 'fury': 570, 'narrow': 875, 'besides': 827, 'begun': 429, 'bring': 757, 'slipped': 521, 'some': 177, 'key': 148, 'rat': 685, 'said': 16, 'cross': 970, 'denial': 1091, 'morning': 502, 'sudden': 363, 'disagree': 722, 'iv': 1147, 'pop': 606, 'pressed': 1043, 'under': 300, 'calling': 1052, 'child': 477, 'lesson': 533, 'are': 106, 'kills': 956, 'shoulders': 695, 'down': 26, 'here': 68, 'door': 95, 'fallen': 311, 'judge': 573, 'pool': 137, 'real': 1175, 'finding': 462, 'wherever': 888, 'hated': 941, 'wet': 547, 'led': 447, 'choked': 1079, 'moderate': 1017, 'once': 98, 'show': 535, 'overhead': 664, 'small': 167, 'lory': 201, 'marked': 224, 'practice': 635, 'leaves': 662, 'walked': 442, 'english': 228, 'stopping': 611, 'occurred': 598, 'listening': 640, 'having': 245, 'duchess': 280, 'know': 62, 'angry': 534, 'written': 649, 'red': 715, 'eaglet': 375, 'our': 197, 'forgotten': 460, 'housemaid': 1165, 'put': 178, 'proceed': 1000, 'almost': 342, 'sir': 500, 'custard': 730, 'fetch': 372, 'new': 420, 'carefully': 1134, 'watch': 392, 'presented': 1062, 'archbishop': 1004, 'trouble': 389, 'existence': 877, 'nothing': 112, 'eyed': 946, 'more': 123, 'useful': 542, 'distance': 315, 'stupid': 385, 'uncomfortable': 971, 'schoolroom': 633, 'since': 1155, 'window': 1180, 'remembered': 349, 'wouldn': 404, 'putting': 867, 'crossed': 839, 'advisable': 557, 'passionate': 927, 'centre': 630, 'don': 171, 'brass': 1168, 'hour': 1041, 'puzzling': 509, 'except': 675, 'particular': 1127, 'right': 158, 'railway': 525, 'straight': 608, 'thousand': 631, 'knew': 451, 'manage': 323, 'directly': 1177, 'minute': 473, 'shrinking': 517, 'trembling': 368, 'heard': 230, 'spoke': 421, 'hoping': 453, 'seems': 360, 'animals': 545, 'until': 805, 'for': 18, 'cause': 364, 'crocodile': 845, 'hole': 243, 'signify': 835, 'even': 258, 'upstairs': 1173, 'quicker': 1115, 'common': 775, 'shrink': 741, 'used': 510, 'yet': 929, 'declared': 1001, 'clinging': 968, 'hurt': 433, 'liked': 563, 'conversations': 589, 'reply': 1110, 'rest': 1047, 'curious': 345, 'jaws': 861, 'people': 216, 'while': 192, 'find': 150, 'passion': 962, 'way': 45, 'paper': 700, 'planning': 791, 'lost': 434, 'anxiously': 276, 'whisper': 1085, 'because': 711, 'cur': 1092, 'expecting': 773, 'curtain': 680, 'believe': 1029, 'through': 144, 'eye': 353, 'commotion': 959, 'generally': 348, 'exactly': 1058, 'eats': 772, 'things': 93, 'feelings': 925, 'my': 70, 'him': 293, 'replied': 378, 'couldn': 655, 'known': 974, 'top': 405, 'everything': 282, 'can': 97, 'hand': 185, 'killing': 624, 'snappishly': 1123, 'claws': 856, 'nurse': 537, 'simple': 712, 'tired': 244, 'many': 310, 'iii': 964, 'face': 346, 'returning': 808, 'been': 166, 'despair': 1054, 'executed': 1150, 'sticks': 661, 'hard': 501, 'pretending': 762, 'second': 679, 'pleaded': 1107, 'half': 149, 'age': 504, 'odd': 794, 'whether': 386, 'old': 292, 'started': 394, 'golden': 188, 'savage': 812, 'ask': 263, 'usurpation': 994, 'party': 240, 'pleasure': 590, 'scolded': 756, 'which': 85, 'reading': 588, 'apple': 732, 'kind': 787, 'cats': 107, 'has': 564, 'delight': 683, 'voice': 233, 'completely': 1158, 'fishes': 858, 'row': 438, 'brightened': 739, 'matter': 428, 'empty': 622, 'pair': 229, 'mentioned': 1143, 'repeat': 841, 'of': 8, 'country': 643, 'inclined': 1034, 'on': 21, 'brave': 628, 'thirteen': 831, 'frightened': 518, 'quiet': 930, 'presents': 793, 'twenty': 833, 'walrus': 905, 'fender': 798, 'atheling': 1013, 'confused': 1053, 'paris': 511, 'leap': 921, 'humbly': 1099, 'taught': 714, 'daresay': 913, 'whole': 290, 'over': 100, 'saw': 400, 'passage': 327, 'yesterday': 819, 'harm': 907, 'out': 31, 'orange': 619, 'catching': 538, 'cat': 267, 'authority': 982, 'he': 111, 'fortunately': 605, 'wanted': 551, 'forehead': 1044, 'dry': 164, 'queer': 234, 'ago': 916, 'rules': 454, 'pounds': 955, 'explain': 561, 'strange': 844, 'rats': 957, 'chatte': 919, 'boots': 789, 'respectable': 765, 'up': 43, 'rapidly': 873, 'telescopes': 698, 'grammar': 910, 'begged': 1081, 'prosecute': 1090, 'else': 266, 'want': 788, 'opened': 446, 'cry': 493, 'immediate': 1025, 'lately': 697, 'prize': 1060, 'coming': 255, 'frog': 1008, 'hold': 458, 'few': 337, 'number': 890, 'disappointment': 621, 'chain': 592, 'twice': 586, 'plate': 1169, 'use': 152, 'panting': 1042, 'story': 575, 'person': 352, 'only': 122, 'bat': 426, 'certain': 343, 'shakespeare': 1046, 'turning': 379, 'wish': 145, 'when': 46, 'sighed': 1117, 'joined': 1112, 'didn': 262, 'advise': 752, 'lose': 1119, 'death': 1097, 'jumped': 663, 'seaside': 885, 'see': 56, 'or': 57, 'legs': 750, 'an': 133, 'do': 49, 'quick': 1161, 'notice': 1010, 'ignorant': 648, 'any': 121, 'seen': 208, 'another': 254, 'escape': 876, 'a': 5, 'speak': 278, 'us': 373, 'sits': 932, 'better': 548, 'guess': 872, 'laugh': 1070, 'along': 334, 'going': 116, 'cheered': 1066, 'hurried': 252, 'again': 54, 'tart': 729, 'punished': 901, 'turkey': 734, 'nine': 492, 'eat': 134, 'violently': 815, 'earth': 410, 'poison': 340, 'sight': 328, 'low': 186, 'sit': 540, 'footsteps': 1146, 'insolence': 1018, 'welcome': 857, 'pairs': 1182, 'nonsense': 491, 'several': 312, 'cake': 355, 'jury': 572, 'esq': 796, 'machines': 892, 'hunting': 579, 'promised': 1082, 'large': 153, 'speech': 567, 'usual': 820, 'patience': 1124, 'blown': 745, 'lamps': 669, 'solemn': 1073, 'sending': 489, 'making': 387, 'tumbling': 626, 'them': 61, 'seven': 832, 'wasting': 1093, 'fifteen': 681, 'clear': 914, 'favoured': 989, 'myself': 786, 'sends': 1148, 'one': 48, 'true': 629, 'complained': 1076, 'foot': 490, 'end': 309, 'afterwards': 597, 'inches': 333, 'grand': 636, 'sand': 894, 'tale': 377, 'familiarly': 973, 'among': 261, 'longer': 667, 'have': 84, 'turned': 220, 'shook': 1113, 'daisies': 594, 'bed': 1139, 'words': 159, 'gloves': 125, 'heads': 318, 'feet': 101, 'take': 253, 'found': 73, 'various': 1140, 'learnt': 632, 'nobody': 577, 'tears': 170, 'beasts': 709, 'read': 704, 'label': 701, 'sounded': 842, 'gave': 474, 'assembled': 965, 'winter': 1035, 're': 322, 'did': 99, 'twelve': 829, 'loveliest': 687, 'guessed': 1152, 'nile': 850, 'showing': 634, 'hanging': 670, 'mabel': 283, 'timid': 814, 'notion': 915, 'nearly': 871, 'everybody': 1048, 'last': 291, 'no': 50, 'brown': 949, 'addressing': 1126, 'shining': 847, 'normans': 1019, 'tell': 146, 'sentence': 920, 'bit': 432, 'toffee': 735, 'pity': 1116, 'telescope': 450, 'till': 868, 'like': 47, 'day': 250, 'struck': 800, 'soothing': 928, 'downward': 638, 'late': 298, 'prizes': 241, 'though': 411, 'insult': 1105, 'allow': 978, 'meaning': 1028, 'hung': 615, 'crab': 576, 'feel': 383, 'slowly': 303, 'thimble': 294, 'caucus': 376, 'home': 308, 'wrong': 838, 'long': 94, 'tone': 196, 'venture': 1128, 'nasty': 942, 's': 36, 'rome': 512, 'curtseying': 647, 'back': 110, 'somewhere': 409, 'sister': 380, 'carrier': 792, 'handed': 1057, 'ann': 581, 'naturedly': 1153, 'round': 108, 'christmas': 790, 'passed': 617, 'well': 127, 'wink': 912, 'dogs': 370, 'cupboards': 398, 'every': 330, 'bank': 381, 'should': 218, 'different': 821, 'shrill': 926, 'bye': 781, 'lazily': 931, 'ready': 232, 'brother': 908, 'kept': 281, 'care': 769, 'noise': 1074, 'position': 1045, 'larger': 448, 'herself': 41, 'running': 562, 'dinner': 951, 'sorrowful': 958, 'quiver': 922, 'must': 69, 'finish': 574, 'buttered': 736, 'tunnel': 609, 'offended': 238, 'doing': 1159, 'fact': 463, 'ah': 503, 'waited': 466, 'refused': 981, 'considering': 382, 'bottle': 273, 'heap': 660, 'shut': 449, 'could': 58, 'you': 12, 'dipped': 610, 'sorts': 508, 'off': 80, 'had': 17, 'remained': 771, 'labelled': 618, 'william': 287, 'purring': 933, 'pointed': 1163, 'white': 128, 'flame': 744, 'think': 60, 'deeply': 719, 'spirited': 1145, 'flashed': 601, 'spread': 855, 'usually': 459, 'latitude': 416, 'edgar': 1012, 'help': 499, 'wooden': 895, 'argument': 975, 'truth': 659, 'before': 130, 'begin': 696, 'glad': 419, 've': 143, 'stairs': 627, 'wondering': 672, 'voices': 1049, 'mercia': 555, 'come': 86, 'much': 91, 'sitting': 585, 'saucer': 651, 'soft': 938, 'its': 114, 'fond': 478, 'made': 206, 'continued': 1020, 'run': 1160, 'tidy': 1179, 'far': 486, 'avoid': 874, 'measure': 870, 'fan': 126, 'ring': 549, 'crying': 470, 'garden': 169, 'life': 356, 'dozing': 656, 'there': 55, 'deep': 302, 'toast': 737, 'pale': 961, 'nor': 596, 'in': 10, 'happened': 336, 'stay': 361, 'stockings': 783, 'near': 259, 'left': 351, 'vanished': 1157, 'learn': 866, 'lying': 354, 'will': 191, 'change': 519, 'own': 247, 'angrily': 1102, 'hearthrug': 797, 'terrier': 947, 'added': 1084, 'pulled': 1055, 'holding': 482, 'confusion': 1075, 'cherry': 728, 'dried': 807, 'cunning': 1095, 'past': 625, 'friends': 713, 'chin': 883, 'behind': 329, 'whose': 988, 'across': 395, 'solid': 674, 'splashing': 903, 'getting': 138, 'canary': 1138, 'meet': 558, 'politely': 999, 'bristling': 939, 'wild': 708, 'knocking': 1172, 'coast': 889, 'ou': 917, 'opportunity': 412, 'shutting': 455, 'aloud': 408, 'nowhere': 1154, 'very': 27, 'jar': 401, 'smile': 1032, 'really': 272, 'thought': 53, 'dare': 1069, 'filled': 397, 'dodo': 90, 'still': 314, 'however': 135, 'listen': 414, 'oyster': 1125, 'with': 23, 'knelt': 686, 'as': 15, 'corner': 435, 'luckily': 1056, 'shiver': 997, 'fear': 402, 'two': 227, 'forgot': 485, 'bowed': 1072, 'case': 524, 'without': 174, 'creep': 768, 'dear': 64, 'whiskers': 437, 'question': 162, 'mind': 248, 'room': 583, 'word': 642, 'll': 37, 'ashamed': 802, 'try': 194, 'course': 204, 'seem': 316, 'walk': 317, 'same': 193, 'either': 140, 'histories': 705, 'inquisitively': 911, 'pocket': 251, 'good': 157, 'let': 105, 'fifth': 1100, 'happen': 304, 'muttering': 498, 'unpleasant': 710, 'others': 1111, 'sooner': 723, 'air': 264, 'multiplication': 834, 'likely': 406, 'sadly': 443, 'fur': 546, 'hope': 650, 'edwin': 552, 'daisy': 591, 'but': 19, 'knife': 720, 'growing': 483, 'sat': 226, 'engraved': 1171, 'pretexts': 1141, 'rising': 1021, 'm': 77, 'dressed': 810, 'bent': 1030, 'grin': 853, 'cool': 692, 'curly': 948, 'eaten': 707, 'poor': 109, 'feeling': 464, 'would': 59, 'hall': 147, 'splash': 882, 'four': 214, 'give': 488, 'now': 81, 'meeting': 1023, 'fire': 935, 'tea': 653, 'latin': 909, 'next': 210, 'set': 776, 'your': 88, 'desperate': 813, 'hands': 514, 'plainly': 748, 'mixed': 726, 'waiting': 452, 'puzzle': 822, 'shoes': 782, 'hundred': 954, 'ordering': 1178, 'drink': 338, 'legged': 673, 'wise': 703, 'salt': 522, 'milk': 652, 'driest': 987}\n",
      "similarity of Alice and Dinah 0.148538649506\n",
      "similarity of Alice and Rabbit 0.0763040737666\n",
      "similarity of Dinah and Rabbit 0.0810361063877\n"
     ]
    }
   ],
   "source": [
    "#find cosine similarity to Alice, Dinah and Rabbit\n",
    "from scipy import spatial\n",
    "print(tokenizer.word_index)\n",
    "\n",
    "def cosine_sim(word_1, word_2, tknzr, matrix):\n",
    "    word_1_ind = tknzr.word_index[word_1]\n",
    "    word_2_ind = tknzr.word_index[word_2]\n",
    "    \n",
    "    #print(word_1, word_1_ind)\n",
    "    #print(word_2, word_2_ind)\n",
    "    \n",
    "    word_1_vec = matrix[:,word_1_ind-1]\n",
    "    word_2_vec = matrix[:,word_2_ind-1]\n",
    "    \n",
    "    #print(word_1_vec)\n",
    "    #print(word_2_vec)\n",
    "    \n",
    "    similarity = 1 - spatial.distance.cosine(word_1_vec, word_2_vec)\n",
    "    #print(similarity)\n",
    "    \n",
    "    return similarity\n",
    "    \n",
    "    \n",
    "print('similarity of Alice and Dinah', str(cosine_sim(\"alice\", \"dinah\", tokenizer, co_occurence)))\n",
    "print('similarity of Alice and Rabbit', str(cosine_sim(\"alice\", \"rabbit\", tokenizer, co_occurence)))\n",
    "print('similarity of Dinah and Rabbit', str(cosine_sim(\"dinah\", \"rabbit\", tokenizer, co_occurence)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word:\n",
      "        Word       Sim\n",
      "511     ugh  0.570483\n",
      "754    ahem  0.570483\n",
      "354     she  0.533538\n",
      "105     say  0.530232\n",
      "75   listen  0.498760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thijs\\Anaconda3\\envs\\Python35\\lib\\site-packages\\scipy\\spatial\\distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "#find the closest words to Alice\n",
    "import pandas as pd\n",
    "\n",
    "similarities = {i: cosine_sim(\"alice\", i, tokenizer, co_occurence) if \"alice\"!= i else 0.0 for i in tokenizer.word_index}\n",
    "pd_similarities = pd.DataFrame(list(similarities.items()), columns=['Word', 'Sim'])\n",
    "\n",
    "top_5 = pd_similarities.sort_values(['Sim'], ascending=False)[:5]\n",
    "\n",
    "print(\"Most similar word:\\n\", top_5)\n",
    "#print(similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion of the drawbacks:\n",
    "\n",
    "One of the major drawbacks of a co-occurence matrix is the fact that the matrix becomes very large in a very short time. In order to compute answers from it one would need a very strong machine. Ofcourse this is doable however, there are more efficient ways to calculate it. Another drawback of using a co-occurence matrix is that quite some memory is needed to be able to store it all in memory. Of course this can be optimalized but still it is quite costly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save your all the vector representations of your word embeddings in this way\n",
    "#Change when necessary the sizes of the vocabulary/embedding dimension\n",
    "\n",
    "f = open('vectors_co_occurrence.txt',\"w\")\n",
    "f.write(\" \".join([str(V-1),str(V-1)]))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "#vectors = your word co-occurrence matrix\n",
    "vectors = co_occurence\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i-1,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reopen your file as follows\n",
    "\n",
    "co_occurrence = KeyedVectors.load_word2vec_format('./vectors_co_occurrence.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### Word embeddings\n",
    "Build embeddings with a keras implementation where the embedding vector is of length 50, 150 and 300. Use the Alice in Wonderland text book for training.\n",
    "1. Using the CBOW model\n",
    "2. Using Skipgram model\n",
    "3. Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer.\n",
    "4. Analyze the four different word embeddings\n",
    "    - Implement your own function to perform the analogy task with. Do not use existing libraries for this task such as Gensim. Your function should be able to answer whether an anaology as in the example given in the pdf-file is true.\n",
    "    - Compare the performance on the analogy task between the word embeddings that you have trained in 2.1, 2.2 and 2.3.  \n",
    "    - Visualize your results and interpret your results\n",
    "5. Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings.  \n",
    "6. Discuss:\n",
    "    - What are the main advantages of CBOW and Skipgram?\n",
    "    - What is the advantage of negative sampling?\n",
    "    - What are the main drawbacks of CBOW and Skipgram?\n",
    "7. Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300\n",
    "    - Compare performance on the analogy task with your own trained embeddings from \"Alice in Wonderland\". You can limit yourself to the vocabulary of Alice in Wonderland. Visualize the pre-trained word embeddings and compare these with the results of your own trained word embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_cbow(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            contexts = []\n",
    "            labels   = []            \n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "            \n",
    "            contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
    "            labels.append(word)\n",
    "\n",
    "            x = sequence.pad_sequences(contexts, maxlen=maxlen)\n",
    "            y = np_utils.to_categorical(labels, V)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=V, output_dim=dim, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim,)))\n",
    "cbow.add(Dense(V, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42308.2811444\n",
      "1 38594.1970193\n",
      "2 38767.0419376\n",
      "3 38867.8861338\n",
      "4 38929.3537067\n",
      "5 38976.922761\n",
      "6 38995.6720477\n",
      "7 39014.251945\n",
      "8 39044.3008515\n",
      "9 39080.0715766\n"
     ]
    }
   ],
   "source": [
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_cbow(corpus, window_size, V):\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow.save('cbow_simple.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_skipgram(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    all_in = []\n",
    "    all_out = []\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            p = index - window_size\n",
    "            n = index + window_size + 1\n",
    "                    \n",
    "            in_words = []\n",
    "            labels = []\n",
    "            for i in range(p, n):\n",
    "                if i != index and 0 <= i < L:\n",
    "                    in_words.append([word])\n",
    "                    labels.append(words[i])\n",
    "            if in_words != []:\n",
    "                all_in.append(np.array(in_words,dtype=np.int32))\n",
    "                all_out.append(np_utils.to_categorical(labels, V))\n",
    "    return (all_in,all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get x and y's for data\n",
    "x,y = generate_data_skipgram(corpus,window_size,V)#save the preprocessed data of Skipgram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data_skipgram.txt' ,'w')\n",
    "\n",
    "for input,outcome  in zip(x,y):\n",
    "    input = np.concatenate(input)\n",
    "    f.write(\" \".join(map(str, list(input))))\n",
    "    f.write(\",\")\n",
    "    outcome = np.concatenate(outcome)\n",
    "    f.write(\" \".join(map(str,list(outcome))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the preprocessed Skipgram data\n",
    "def generate_data_skipgram_from_file():\n",
    "    f = open('data_skipgram.txt' ,'r')\n",
    "    for row in f:\n",
    "        inputs,outputs = row.split(\",\")\n",
    "        inputs = np.fromstring(inputs, dtype=int, sep=' ')\n",
    "        inputs = np.asarray(np.split(inputs, len(inputs)))\n",
    "        outputs = np.fromstring(outputs, dtype=float, sep=' ')\n",
    "        outputs = np.asarray(np.split(outputs, len(inputs)))\n",
    "        yield (inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram = Sequential()\n",
    "skipgram.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram.add(Reshape((dim, )))\n",
    "skipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42008.0517182\n",
      "1 38353.1881878\n",
      "2 38921.1881423\n",
      "3 39330.0949223\n",
      "4 39505.6043484\n",
      "5 39678.1267002\n",
      "6 39847.5325572\n",
      "7 40026.978894\n",
      "8 40211.2500122\n",
      "9 40398.6335881\n"
     ]
    }
   ],
   "source": [
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.save('skipgram_simple.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation for the dense layer\n",
    "\n",
    "As can be seen below we tried several different activation functions as an extra dense layer. After some research online we decided that at least we wanted to test both ELU and ReLU as activation functions. Apart from these two functions we also wanted to try one else which became Sigmoid. Since ELU and ReLU both are quite good with dealing with vanishing gradients we felt like we needed another layer which strong point was not dealing with the vanishing gradient. Even though Sigmoid and Softmax show similarities we wanted to at least try it to make sure that indeed it would not be the best solution. And as can be seen below it indeed was not the best choice as a second dense layer. \n",
    "\n",
    "Because we did not know which one would perform best we decided that we would try all three. We put the activation layers in before the Softmax layer since Softmax is usually used as the last layer in the hidden layers of a neural network. This because Softmax normalizes the results while minimizing the cross-entropy/negative likelihood between the predictions and the actual outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Thijs\\Anaconda3\\envs\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#create CBOW model with additional dense layer        \n",
    "dcbow = Sequential()\n",
    "dcbow.add(Embedding(input_dim=V, output_dim=dim, input_length=window_size*2))\n",
    "dcbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim,)))\n",
    "dcbow.add(Dense(V, activation='elu'))\n",
    "#dcbow.add(Dense(V, activation='sigmoid'))\n",
    "#dcbow.add(Dense(V, activation='relu'))\n",
    "dcbow.add(Dense(V, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for CBOW + dense\n",
    "dcbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39850.4765533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-538e6c1b5b90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgenerate_data_cbow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdcbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    979\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[0;32m    980\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m                                          class_weight=class_weight)\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train model for CBOW + dense elu activation\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_cbow(corpus, window_size, V):\n",
    "        loss += dcbow.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbow.save('dcbow_elu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42573.9224706\n",
      "1 40779.2916886\n",
      "2 40212.4141967\n",
      "3 40963.4117401\n",
      "4 42315.4382861\n",
      "5 43557.8121278\n",
      "6 44557.614516\n",
      "7 45347.3085792\n",
      "8 45826.0357494\n",
      "9 45717.4792516\n"
     ]
    }
   ],
   "source": [
    "#train model for CBOW + dense sigmoid activation\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_cbow(corpus, window_size, V):\n",
    "        loss += dcbow.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbow.save('dcbow_Sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 40066.6369147\n",
      "1 38122.0871696\n",
      "2 37527.2364669\n",
      "3 37265.8932388\n",
      "4 37098.9213078\n",
      "5 36907.566846\n",
      "6 36689.9979763\n",
      "7 36465.4231402\n",
      "8 36250.071865\n",
      "9 36031.9165194\n"
     ]
    }
   ],
   "source": [
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_cbow(corpus, window_size, V):\n",
    "        loss += dcbow.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcbow.save('dcbow_Relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram with additional dense layer\n",
    "dskipgram = Sequential()\n",
    "dskipgram.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "dskipgram.add(Reshape((dim, )))\n",
    "dskipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='elu'))\n",
    "dskipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Thijs\\Anaconda3\\envs\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Thijs\\Anaconda3\\envs\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#define loss function for Skipgram + dense\n",
    "dskipgram.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39171.4094963\n",
      "1 37593.4716475\n",
      "2 37049.7866344\n",
      "3 36863.5996245\n",
      "4 36989.3757836\n",
      "5 37082.103549\n",
      "6 37015.1577585\n",
      "7 36882.7768184\n",
      "8 36745.6724875\n",
      "9 36615.3105249\n"
     ]
    }
   ],
   "source": [
    "#train model for Skipgram + dense\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += dskipgram.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dskipgram.save('dskipgram_elu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram with additional dense layer\n",
    "dskipgram = Sequential()\n",
    "dskipgram.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "dskipgram.add(Reshape((dim, )))\n",
    "dskipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='sigmoid'))\n",
    "dskipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram + dense\n",
    "dskipgram.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39699.7591234\n",
      "1 39342.0153301\n",
      "2 39097.7367924\n",
      "3 38975.9978857\n",
      "4 39085.1981041\n",
      "5 39359.1998932\n",
      "6 39351.1995022\n",
      "7 39203.5751615\n",
      "8 39015.3584349\n",
      "9 38764.1542244\n"
     ]
    }
   ],
   "source": [
    "#train model for Skipgram + dense\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += dskipgram.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dskipgram.save('dskipgram_sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram with additional dense layer\n",
    "dskipgram = Sequential()\n",
    "dskipgram.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "dskipgram.add(Reshape((dim, )))\n",
    "dskipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='relu'))\n",
    "dskipgram.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram + dense\n",
    "dskipgram.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39437.579227\n",
      "1 38211.8743823\n",
      "2 37820.7792289\n",
      "3 37606.3476986\n",
      "4 37546.8119706\n",
      "5 37517.1473264\n",
      "6 37465.703705\n",
      "7 37408.8727797\n",
      "8 37353.1536354\n",
      "9 37295.5879925\n"
     ]
    }
   ],
   "source": [
    "#train model for Skipgram + dense\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += dskipgram.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dskipgram.save('dskipgram_Relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudden', 'suddenly', 'usual', 'usually'] False\n",
      "['bad', 'worse', 'good', 'better'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['he', 'she', 'his', 'her'] False\n",
      "['brother', 'sister', 'his', 'her'] False\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['saying', 'said', 'thinking', 'thought'] False\n",
      "['bird', 'birds', 'cat', 'cats'] False\n",
      "['good', 'better', 'old', 'older'] False\n",
      "['good', 'better', 'quick', 'quicker'] False\n",
      "['large', 'largest', 'good', 'best'] False\n",
      "['falling', 'fell', 'knowing', 'knew'] False\n",
      "['walk', 'walking', 'think', 'thinking'] False\n",
      "['child', 'children', 'cat', 'cats'] False\n",
      "['dog', 'dogs', 'eye', 'eyes'] True\n",
      "['hand', 'hands', 'rat', 'rats'] False\n",
      "['eat', 'eats', 'find', 'finds'] False\n",
      "['find', 'finds', 'say', 'says'] True\n",
      "['old', 'older', 'good', 'better'] False\n",
      "['large', 'larger', 'quick', 'quicker'] False\n",
      "['go', 'going', 'listen', 'listening'] False\n",
      "['run', 'running', 'walk', 'walking'] False\n",
      "['run', 'running', 'think', 'thinking'] False\n",
      "['say', 'saying', 'sit', 'sitting'] False\n",
      "['alice', 'she', 'rabbit', 'he'] False\n",
      "['alice', 'her', 'rabbit', 'him'] True\n",
      "['alice', 'girl', 'rabbit', 'sir'] False\n",
      "['dinah', 'cat', 'alice', 'girl'] False\n",
      "['his', 'her', 'he', 'she'] False\n",
      "['long', 'longer', 'quick', 'quicker'] False\n",
      "['long', 'longer', 'small', 'smaller'] False\n",
      "['long', 'longer', 'bad', 'worse'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['swim', 'swimming', 'sit', 'sitting'] False\n",
      "['run', 'running', 'listen', 'listening'] False\n",
      "['think', 'thinking', 'read', 'reading'] False\n",
      "['up', 'down', 'close', 'far'] False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "path_anal = 'Data/analogy_alice.txt'\n",
    "corpus_anal = open(path_anal).readlines()[0:47]\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "corpus_anal = [sentence for sentence in corpus_anal if sentence.count(\" \") >= 2]\n",
    "corpus_anal = [sentence.split() for sentence in corpus_anal]\n",
    "corpus_anal_words = deepcopy(corpus_anal)\n",
    "weights = co_occurence\n",
    "\n",
    "def analogy(weights, corpus_anal):\n",
    "    for i, sentence in enumerate(corpus_anal):\n",
    "            for j in range(len(sentence)):\n",
    "                try:\n",
    "                    sentence[j] = tokenizer.word_index[sentence[j]]\n",
    "                except:\n",
    "                    #print(\"One or more words not in vocabulary\")\n",
    "                    pass\n",
    "            if type(sentence[0]) == type(sentence[1]) == type(sentence[2]) == type(sentence[3]) == int:\n",
    "                co_occurence_output = weights[sentence[0]-1] - weights[sentence[1]-1] + weights[sentence[2]-1]\n",
    "                ground_truth = weights[sentence[3]-1]\n",
    "                similarity = 1 - spatial.distance.cosine(co_occurence_output, ground_truth)\n",
    "                #print(corpus_anal_words[i], similarity)\n",
    "                if(similarity > 0.1):\n",
    "                    print(corpus_anal_words[i], True)\n",
    "                else:\n",
    "                    print(corpus_anal_words[i], False)\n",
    "            # bereken cosine\n",
    "\n",
    "    #print(corpus_anal)\n",
    "\n",
    "analogy(weights, corpus_anal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudden', 'suddenly', 'usual', 'usually'] False\n",
      "['bad', 'worse', 'good', 'better'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['he', 'she', 'his', 'her'] False\n",
      "['brother', 'sister', 'his', 'her'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['saying', 'said', 'thinking', 'thought'] False\n",
      "['bird', 'birds', 'cat', 'cats'] True\n",
      "['good', 'better', 'old', 'older'] False\n",
      "['good', 'better', 'quick', 'quicker'] False\n",
      "['large', 'largest', 'good', 'best'] True\n",
      "['falling', 'fell', 'knowing', 'knew'] False\n",
      "['walk', 'walking', 'think', 'thinking'] False\n",
      "['child', 'children', 'cat', 'cats'] True\n",
      "['dog', 'dogs', 'eye', 'eyes'] False\n",
      "['hand', 'hands', 'rat', 'rats'] False\n",
      "['eat', 'eats', 'find', 'finds'] False\n",
      "['find', 'finds', 'say', 'says'] False\n",
      "['old', 'older', 'good', 'better'] False\n",
      "['large', 'larger', 'quick', 'quicker'] False\n",
      "['go', 'going', 'listen', 'listening'] False\n",
      "['run', 'running', 'walk', 'walking'] False\n",
      "['run', 'running', 'think', 'thinking'] False\n",
      "['say', 'saying', 'sit', 'sitting'] False\n",
      "['alice', 'she', 'rabbit', 'he'] True\n",
      "['alice', 'her', 'rabbit', 'him'] True\n",
      "['alice', 'girl', 'rabbit', 'sir'] True\n",
      "['dinah', 'cat', 'alice', 'girl'] False\n",
      "['his', 'her', 'he', 'she'] False\n",
      "['long', 'longer', 'quick', 'quicker'] False\n",
      "['long', 'longer', 'small', 'smaller'] False\n",
      "['long', 'longer', 'bad', 'worse'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['swim', 'swimming', 'sit', 'sitting'] False\n",
      "['run', 'running', 'listen', 'listening'] False\n",
      "['think', 'thinking', 'read', 'reading'] False\n",
      "['up', 'down', 'close', 'far'] False\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('dcbow_elu.h5')\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "analogy(weights, corpus_anal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudden', 'suddenly', 'usual', 'usually'] False\n",
      "['bad', 'worse', 'good', 'better'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['he', 'she', 'his', 'her'] False\n",
      "['brother', 'sister', 'his', 'her'] False\n",
      "['listen', 'listening', 'look', 'looking'] False\n",
      "['saying', 'said', 'thinking', 'thought'] False\n",
      "['bird', 'birds', 'cat', 'cats'] False\n",
      "['good', 'better', 'old', 'older'] True\n",
      "['good', 'better', 'quick', 'quicker'] False\n",
      "['large', 'largest', 'good', 'best'] False\n",
      "['falling', 'fell', 'knowing', 'knew'] False\n",
      "['walk', 'walking', 'think', 'thinking'] False\n",
      "['child', 'children', 'cat', 'cats'] True\n",
      "['dog', 'dogs', 'eye', 'eyes'] False\n",
      "['hand', 'hands', 'rat', 'rats'] True\n",
      "['eat', 'eats', 'find', 'finds'] False\n",
      "['find', 'finds', 'say', 'says'] False\n",
      "['old', 'older', 'good', 'better'] False\n",
      "['large', 'larger', 'quick', 'quicker'] False\n",
      "['go', 'going', 'listen', 'listening'] False\n",
      "['run', 'running', 'walk', 'walking'] False\n",
      "['run', 'running', 'think', 'thinking'] False\n",
      "['say', 'saying', 'sit', 'sitting'] False\n",
      "['alice', 'she', 'rabbit', 'he'] False\n",
      "['alice', 'her', 'rabbit', 'him'] False\n",
      "['alice', 'girl', 'rabbit', 'sir'] False\n",
      "['dinah', 'cat', 'alice', 'girl'] False\n",
      "['his', 'her', 'he', 'she'] False\n",
      "['long', 'longer', 'quick', 'quicker'] True\n",
      "['long', 'longer', 'small', 'smaller'] False\n",
      "['long', 'longer', 'bad', 'worse'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['listen', 'listening', 'look', 'looking'] False\n",
      "['swim', 'swimming', 'sit', 'sitting'] False\n",
      "['run', 'running', 'listen', 'listening'] False\n",
      "['think', 'thinking', 'read', 'reading'] False\n",
      "['up', 'down', 'close', 'far'] False\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('dskipgram_elu.h5')\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "analogy(weights, corpus_anal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudden', 'suddenly', 'usual', 'usually'] False\n",
      "['bad', 'worse', 'good', 'better'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['he', 'she', 'his', 'her'] False\n",
      "['brother', 'sister', 'his', 'her'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['saying', 'said', 'thinking', 'thought'] False\n",
      "['bird', 'birds', 'cat', 'cats'] True\n",
      "['good', 'better', 'old', 'older'] False\n",
      "['good', 'better', 'quick', 'quicker'] False\n",
      "['large', 'largest', 'good', 'best'] True\n",
      "['falling', 'fell', 'knowing', 'knew'] False\n",
      "['walk', 'walking', 'think', 'thinking'] False\n",
      "['child', 'children', 'cat', 'cats'] True\n",
      "['dog', 'dogs', 'eye', 'eyes'] False\n",
      "['hand', 'hands', 'rat', 'rats'] False\n",
      "['eat', 'eats', 'find', 'finds'] False\n",
      "['find', 'finds', 'say', 'says'] False\n",
      "['old', 'older', 'good', 'better'] False\n",
      "['large', 'larger', 'quick', 'quicker'] False\n",
      "['go', 'going', 'listen', 'listening'] False\n",
      "['run', 'running', 'walk', 'walking'] False\n",
      "['run', 'running', 'think', 'thinking'] False\n",
      "['say', 'saying', 'sit', 'sitting'] False\n",
      "['alice', 'she', 'rabbit', 'he'] True\n",
      "['alice', 'her', 'rabbit', 'him'] True\n",
      "['alice', 'girl', 'rabbit', 'sir'] True\n",
      "['dinah', 'cat', 'alice', 'girl'] False\n",
      "['his', 'her', 'he', 'she'] False\n",
      "['long', 'longer', 'quick', 'quicker'] False\n",
      "['long', 'longer', 'small', 'smaller'] False\n",
      "['long', 'longer', 'bad', 'worse'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['swim', 'swimming', 'sit', 'sitting'] False\n",
      "['run', 'running', 'listen', 'listening'] False\n",
      "['think', 'thinking', 'read', 'reading'] False\n",
      "['up', 'down', 'close', 'far'] False\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cbow_simple.h5')\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "analogy(weights, corpus_anal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudden', 'suddenly', 'usual', 'usually'] False\n",
      "['bad', 'worse', 'good', 'better'] False\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['he', 'she', 'his', 'her'] False\n",
      "['brother', 'sister', 'his', 'her'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['saying', 'said', 'thinking', 'thought'] False\n",
      "['bird', 'birds', 'cat', 'cats'] True\n",
      "['good', 'better', 'old', 'older'] False\n",
      "['good', 'better', 'quick', 'quicker'] False\n",
      "['large', 'largest', 'good', 'best'] True\n",
      "['falling', 'fell', 'knowing', 'knew'] False\n",
      "['walk', 'walking', 'think', 'thinking'] False\n",
      "['child', 'children', 'cat', 'cats'] True\n",
      "['dog', 'dogs', 'eye', 'eyes'] False\n",
      "['hand', 'hands', 'rat', 'rats'] False\n",
      "['eat', 'eats', 'find', 'finds'] True\n",
      "['find', 'finds', 'say', 'says'] True\n",
      "['old', 'older', 'good', 'better'] False\n",
      "['large', 'larger', 'quick', 'quicker'] True\n",
      "['go', 'going', 'listen', 'listening'] False\n",
      "['run', 'running', 'walk', 'walking'] False\n",
      "['run', 'running', 'think', 'thinking'] False\n",
      "['say', 'saying', 'sit', 'sitting'] False\n",
      "['alice', 'she', 'rabbit', 'he'] True\n",
      "['alice', 'her', 'rabbit', 'him'] False\n",
      "['alice', 'girl', 'rabbit', 'sir'] True\n",
      "['dinah', 'cat', 'alice', 'girl'] False\n",
      "['his', 'her', 'he', 'she'] False\n",
      "['long', 'longer', 'quick', 'quicker'] False\n",
      "['long', 'longer', 'small', 'smaller'] True\n",
      "['long', 'longer', 'bad', 'worse'] True\n",
      "['go', 'going', 'look', 'looking'] True\n",
      "['listen', 'listening', 'look', 'looking'] True\n",
      "['swim', 'swimming', 'sit', 'sitting'] False\n",
      "['run', 'running', 'listen', 'listening'] False\n",
      "['think', 'thinking', 'read', 'reading'] False\n",
      "['up', 'down', 'close', 'far'] False\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('skipgram_simple.h5')\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "analogy(weights, corpus_anal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1182 samples in 0.040s...\n",
      "[t-SNE] Computed neighbors for 1182 samples in 2.872s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1182\n",
      "[t-SNE] Computed conditional probabilities for sample 1182 / 1182\n",
      "[t-SNE] Mean sigma: 0.025614\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 95.183945\n",
      "[t-SNE] Error after 1000 iterations: 1.535138\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ab767b2cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization results trained word embeddings\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize(weights):\n",
    "    n_sne = 1000\n",
    "    tsne = TSNE(verbose=1)\n",
    "    tsne_results = tsne.fit_transform(weights)\n",
    "\n",
    "    df_tsne = {}\n",
    "    df_tsne['x-tsne'] = tsne_results[:,0]\n",
    "    df_tsne['y-tsne'] = tsne_results[:,1]\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.scatter(df_tsne['x-tsne'], df_tsne['y-tsne'])\n",
    "\n",
    "visualize(co_occurence[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1183 samples in 0.004s...\n",
      "[t-SNE] Computed neighbors for 1183 samples in 0.281s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1183\n",
      "[t-SNE] Computed conditional probabilities for sample 1183 / 1183\n",
      "[t-SNE] Mean sigma: 0.109482\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 82.976036\n",
      "[t-SNE] Error after 1000 iterations: 2.740622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ab779bc5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('skipgram_simple.h5')\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "visualize(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation results of the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of the trained word embeddings with the word-word co-occurrence matrix:\n",
    "\n",
    "Comparison performance:\n",
    "\n",
    "In the results above you can see that looking at the the different methods we do find some correlation. It can be seen that there are only two collection of words on which all models agree that they are similar. That are the combinations of ['go', 'going', 'look', 'looking'] and ['listen', 'listening', 'look', 'looking']. What is curious is that in both examples the words look and looking are present. \n",
    "\n",
    "Apart from that it is noticable that our own analogy perfoms like the CBOW and Skipgram models with only one dense level. There are some collection of words on which it only agrees with one of the two models or non of the two models. But in general our own analogy agrees more with the one dense function CBOW and Skipgram agree more than compared to the extra dense CBOW and Skipgram model. \n",
    "\n",
    "However, it it worth mentioning that the extra dense models tend to agree with eachother meaning that if one evaluates to true the other also evaluates to true. This might be due to the fact that the same activation functions have been used.\n",
    "\n",
    "Finally it is important to mention that we used hardcoded values to determine whether a collection of words evaluates to true or false within a specific model. It could be improved by using the nearest neighbour of the outcomming vector and compare that to the vector of the word which we expect it to be. We expect this method to result in more reliable results than hardcoding the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the advantages of CBOW and Skipgram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the advantages of negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the drawbacks of CBOW and Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your path /GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-9ecd3e6043a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath_word2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"your path /GoogleNews-vectors-negative300.bin\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mword2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_word2vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1002\u001b[0m             \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_ERRORS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfile_smart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"s3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s3n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's3u'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ms3_open_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mfile_smart_open\u001b[1;34m(fname, mode, encoding, errors)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mraw_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m     \u001b[0mraw_fobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m     \u001b[0mdecompressed_fobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_fobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[0mdecoded_fobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoding_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecompressed_fobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your path /GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "#load pretrained word embeddings of word2vec\n",
    "\n",
    "path_word2vec = \"Data/GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(path_word2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'the'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-e0671b67789a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglove2word2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"glove_converted.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mglove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1002\u001b[0m             \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python35\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'the'"
     ]
    }
   ],
   "source": [
    "from gensim.scripts import glove2word2vec\n",
    "#load pretraind word embeddings of Glove\n",
    "\n",
    "path = \"data/glove.6B/glove.6B.300d.txt\"\n",
    "\n",
    "#convert GloVe into word2vec format\n",
    "gensim.scripts.glove2word2vec.get_glove_info(path)\n",
    "gensim.scripts.glove2word2vec.glove2word2vec(path, \"glove_converted.txt\")\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format(path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison performance with your own trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
